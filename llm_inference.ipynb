{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN4VDbIu+0ywV+YUMITjI5w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c22b8879f4b34e4a8dd420d68cfdd797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f72d6f70943245c4b2411c6adefbeb10",
              "IPY_MODEL_151afb38ddb84602ba3a030dcd61a84b",
              "IPY_MODEL_699d6b5ffbd043ad8822920efb13a1d7"
            ],
            "layout": "IPY_MODEL_de7fc063687044b7a8d20c2270cc95ae"
          }
        },
        "f72d6f70943245c4b2411c6adefbeb10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb5548eb5b59430ba3e83410caedef4d",
            "placeholder": "​",
            "style": "IPY_MODEL_d6c89a14276a437285a3ad38cbc49fcb",
            "value": "config.json: 100%"
          }
        },
        "151afb38ddb84602ba3a030dcd61a84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a70302754294cc39f027fba871e2aca",
            "max": 662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2da57fb2cec8429fab0c7d49374cd2ea",
            "value": 662
          }
        },
        "699d6b5ffbd043ad8822920efb13a1d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88f963333c514e3d947d735feaa95278",
            "placeholder": "​",
            "style": "IPY_MODEL_1ae4403751dd40d79872c2e7d2ae0758",
            "value": " 662/662 [00:00&lt;00:00, 51.2kB/s]"
          }
        },
        "de7fc063687044b7a8d20c2270cc95ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb5548eb5b59430ba3e83410caedef4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6c89a14276a437285a3ad38cbc49fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a70302754294cc39f027fba871e2aca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2da57fb2cec8429fab0c7d49374cd2ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88f963333c514e3d947d735feaa95278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ae4403751dd40d79872c2e7d2ae0758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57c31afee6c944ccb38b4a2f268f7d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_622926d04e164f6a9f4f96b8acaa00c9",
              "IPY_MODEL_1665b37ad6774f4ca01099a4c36c1c7a",
              "IPY_MODEL_c42d93dca83345e1ae62d1b6e7ebf990"
            ],
            "layout": "IPY_MODEL_6a43ef5b29f84181905c1559ba0ef19e"
          }
        },
        "622926d04e164f6a9f4f96b8acaa00c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12473150cfca47fd8d8b1eee6b926e1b",
            "placeholder": "​",
            "style": "IPY_MODEL_7f5fa96b9b7f4d3585a6081500c10d07",
            "value": "model.safetensors: 100%"
          }
        },
        "1665b37ad6774f4ca01099a4c36c1c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_095152560d974eb29ad9c5013d99d3cb",
            "max": 3673690696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc2bd98c532e4c15bf6cf0138bbfce24",
            "value": 3673690696
          }
        },
        "c42d93dca83345e1ae62d1b6e7ebf990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1c3a584eec3460aa4809b2d7bc73829",
            "placeholder": "​",
            "style": "IPY_MODEL_e8a1ad3e26a3411f858b996fe6024e4f",
            "value": " 3.67G/3.67G [01:27&lt;00:00, 42.2MB/s]"
          }
        },
        "6a43ef5b29f84181905c1559ba0ef19e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12473150cfca47fd8d8b1eee6b926e1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f5fa96b9b7f4d3585a6081500c10d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "095152560d974eb29ad9c5013d99d3cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc2bd98c532e4c15bf6cf0138bbfce24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1c3a584eec3460aa4809b2d7bc73829": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8a1ad3e26a3411f858b996fe6024e4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff60733f9a3845ad86acae85023cdf9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e9dbee5127541f7a3c83988da51bf86",
              "IPY_MODEL_600d8c7ac0dc4fa7880879acf4b2a690",
              "IPY_MODEL_8ad8b98039c449499f9cb475734219e5"
            ],
            "layout": "IPY_MODEL_60e200fefb2b4bba8f9ed5e9053b9c0f"
          }
        },
        "4e9dbee5127541f7a3c83988da51bf86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_086a055c92e1484896e632f1c9733b5c",
            "placeholder": "​",
            "style": "IPY_MODEL_a3b86b7c2a5c48e8a5a62a564d93ddf5",
            "value": "generation_config.json: 100%"
          }
        },
        "600d8c7ac0dc4fa7880879acf4b2a690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c950f3e085814bfe9027e4bc501e4d61",
            "max": 206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f741886996a846888316683d5d3795ba",
            "value": 206
          }
        },
        "8ad8b98039c449499f9cb475734219e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57f42deb21a64537a5bd33f4c9c56d8a",
            "placeholder": "​",
            "style": "IPY_MODEL_bbc7e33aa40e402d8323c6ab65fbf27e",
            "value": " 206/206 [00:00&lt;00:00, 18.1kB/s]"
          }
        },
        "60e200fefb2b4bba8f9ed5e9053b9c0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "086a055c92e1484896e632f1c9733b5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3b86b7c2a5c48e8a5a62a564d93ddf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c950f3e085814bfe9027e4bc501e4d61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f741886996a846888316683d5d3795ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57f42deb21a64537a5bd33f4c9c56d8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbc7e33aa40e402d8323c6ab65fbf27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c1fe4cb4dba404a83d42ac8f38d53d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb2b0688844d4165b518d35b6a6e6e56",
              "IPY_MODEL_e42c582e67ec41438f84959798557021",
              "IPY_MODEL_b21d44e333f0441985deec7db1983fc8"
            ],
            "layout": "IPY_MODEL_f07bb9874b764072a5a910ac332f203c"
          }
        },
        "fb2b0688844d4165b518d35b6a6e6e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7dc1f5422de4f68935e8cde34204ed2",
            "placeholder": "​",
            "style": "IPY_MODEL_b1def8b2760142229bd1f25fe3aedcc2",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e42c582e67ec41438f84959798557021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70a53574cf5d4061aebcff0e3a171b0f",
            "max": 1287,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d982e5e2ad9b4b4f928b8ebb0390593e",
            "value": 1287
          }
        },
        "b21d44e333f0441985deec7db1983fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7962de74990341f3a3f4e8f37681080f",
            "placeholder": "​",
            "style": "IPY_MODEL_21d3b8e22303490ebc726d93f41908fc",
            "value": " 1.29k/1.29k [00:00&lt;00:00, 87.2kB/s]"
          }
        },
        "f07bb9874b764072a5a910ac332f203c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7dc1f5422de4f68935e8cde34204ed2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1def8b2760142229bd1f25fe3aedcc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70a53574cf5d4061aebcff0e3a171b0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d982e5e2ad9b4b4f928b8ebb0390593e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7962de74990341f3a3f4e8f37681080f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21d3b8e22303490ebc726d93f41908fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00f083e314bb48c1abdc1303a1a4cfa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7972f6ea86e24b98bffa63100dda9cfd",
              "IPY_MODEL_5da4616f04ec4e1a8f405e0bab02f54f",
              "IPY_MODEL_06ece4f0bc264d92af1bfb7977bd9342"
            ],
            "layout": "IPY_MODEL_8d74cbfe37e14cffae4cb088dffac302"
          }
        },
        "7972f6ea86e24b98bffa63100dda9cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e60f3ec6a674c5bb5dbb552a12f8321",
            "placeholder": "​",
            "style": "IPY_MODEL_40053ed145064565a872cafae44ed0b0",
            "value": "vocab.json: 100%"
          }
        },
        "5da4616f04ec4e1a8f405e0bab02f54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b37a35b3b9be441693553d07b77edb2b",
            "max": 2776833,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35ad1399dd1541d787cec6da6bdf0602",
            "value": 2776833
          }
        },
        "06ece4f0bc264d92af1bfb7977bd9342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a46e05f8c9949d1a985374a977f0d74",
            "placeholder": "​",
            "style": "IPY_MODEL_75911f77f1e4498e9c2d7a91a763d443",
            "value": " 2.78M/2.78M [00:03&lt;00:00, 784kB/s]"
          }
        },
        "8d74cbfe37e14cffae4cb088dffac302": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e60f3ec6a674c5bb5dbb552a12f8321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40053ed145064565a872cafae44ed0b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b37a35b3b9be441693553d07b77edb2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35ad1399dd1541d787cec6da6bdf0602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a46e05f8c9949d1a985374a977f0d74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75911f77f1e4498e9c2d7a91a763d443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59c02d321c5243a8899d0ed866d291c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_139371307dd24d1eb31c77c69a89c21c",
              "IPY_MODEL_62818bcb8d6a4d3f9f97a97b01051e87",
              "IPY_MODEL_5ff80a3cbb0340af93689371f97806f6"
            ],
            "layout": "IPY_MODEL_b02b16e43956420183df2463b3252dff"
          }
        },
        "139371307dd24d1eb31c77c69a89c21c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b547701d154c40c48c7f2053068e894c",
            "placeholder": "​",
            "style": "IPY_MODEL_3871290960404eafb6028aebe8cadee3",
            "value": "merges.txt: 100%"
          }
        },
        "62818bcb8d6a4d3f9f97a97b01051e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c76985c4b6545b1a460a1658ce6f93d",
            "max": 1671839,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a05f77ca05374d04838af44941280587",
            "value": 1671839
          }
        },
        "5ff80a3cbb0340af93689371f97806f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9092f67331f94be089dca31c9f2e3cf4",
            "placeholder": "​",
            "style": "IPY_MODEL_cedb15bb75964e888b12b8ec17c823b2",
            "value": " 1.67M/1.67M [00:02&lt;00:00, 591kB/s]"
          }
        },
        "b02b16e43956420183df2463b3252dff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b547701d154c40c48c7f2053068e894c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3871290960404eafb6028aebe8cadee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c76985c4b6545b1a460a1658ce6f93d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a05f77ca05374d04838af44941280587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9092f67331f94be089dca31c9f2e3cf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cedb15bb75964e888b12b8ec17c823b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fd7cf4ff9ee4cfba76a9eafb0abf188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_782a340fa8dc4aeba2de54b9ef950d80",
              "IPY_MODEL_4c6ffc30e18c43b3997dff47dceea3b5",
              "IPY_MODEL_e506000cfdf84f8a98f50fb7cca9cf20"
            ],
            "layout": "IPY_MODEL_6b1d930621bd4a36a1c0ed0474933e3d"
          }
        },
        "782a340fa8dc4aeba2de54b9ef950d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fb80e28acc64df3bafa8c13d07896ff",
            "placeholder": "​",
            "style": "IPY_MODEL_f58de4207b59454d983d94ec3656e2c0",
            "value": "tokenizer.json: 100%"
          }
        },
        "4c6ffc30e18c43b3997dff47dceea3b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d95d70ae903f4a71ab86e6d1c63e32bf",
            "max": 7028015,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a917bdab57ff4d9caba689c115a49316",
            "value": 7028015
          }
        },
        "e506000cfdf84f8a98f50fb7cca9cf20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e1a4127e4404cf3834d0e392567e911",
            "placeholder": "​",
            "style": "IPY_MODEL_2ec9441391c740d588c9b37cec35e6f3",
            "value": " 7.03M/7.03M [00:00&lt;00:00, 9.95MB/s]"
          }
        },
        "6b1d930621bd4a36a1c0ed0474933e3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fb80e28acc64df3bafa8c13d07896ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f58de4207b59454d983d94ec3656e2c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d95d70ae903f4a71ab86e6d1c63e32bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a917bdab57ff4d9caba689c115a49316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e1a4127e4404cf3834d0e392567e911": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ec9441391c740d588c9b37cec35e6f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d11564dceb294fb9813b3e1646a29bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1e8f82636904bd5ab8902df05c8bf6b",
              "IPY_MODEL_f4521dc78ed845d78c677c4d65359be5",
              "IPY_MODEL_e3433fa7602c486f84a7667416e85fd1"
            ],
            "layout": "IPY_MODEL_79d300d1241547e38e39546339a97119"
          }
        },
        "b1e8f82636904bd5ab8902df05c8bf6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7301a847922940688c4015fcf734cf37",
            "placeholder": "​",
            "style": "IPY_MODEL_0537087ee0a54a878243bb3f18d6b28d",
            "value": "config.json: 100%"
          }
        },
        "f4521dc78ed845d78c677c4d65359be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cad4ab7878884b3bba21dc6591477518",
            "max": 659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9863390b0f384af8bfcd6423c98c985b",
            "value": 659
          }
        },
        "e3433fa7602c486f84a7667416e85fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_551607401df447c29e9010feb3ca3ef9",
            "placeholder": "​",
            "style": "IPY_MODEL_06fe437bd74b4b29af233dcc52da8df3",
            "value": " 659/659 [00:00&lt;00:00, 57.5kB/s]"
          }
        },
        "79d300d1241547e38e39546339a97119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7301a847922940688c4015fcf734cf37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0537087ee0a54a878243bb3f18d6b28d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cad4ab7878884b3bba21dc6591477518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9863390b0f384af8bfcd6423c98c985b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "551607401df447c29e9010feb3ca3ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06fe437bd74b4b29af233dcc52da8df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11ab7e1ce6fd4fb394a68bb5f92ccc38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47fc2fef5bb0457ca1d4b4cb48b4f166",
              "IPY_MODEL_82777cb8f33941888966fd52052590ff",
              "IPY_MODEL_5b42332c54304e6b9975f6f176b51b55"
            ],
            "layout": "IPY_MODEL_4d34be021dda4e3b89f51630630f7502"
          }
        },
        "47fc2fef5bb0457ca1d4b4cb48b4f166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78f2f1c445b145858bbb37166f1af320",
            "placeholder": "​",
            "style": "IPY_MODEL_6dd8809a125943d4886831723e6198d5",
            "value": "model.safetensors: 100%"
          }
        },
        "82777cb8f33941888966fd52052590ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d02c3860c3694e39bf75ff7d21539f5d",
            "max": 988097824,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed80d9b5877f4c78959f0cc7023b985d",
            "value": 988097824
          }
        },
        "5b42332c54304e6b9975f6f176b51b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_756c1fb3559a41a68e7c8ad7ce438853",
            "placeholder": "​",
            "style": "IPY_MODEL_c2b59c62453f4850a1d251a2e56fff20",
            "value": " 988M/988M [00:23&lt;00:00, 43.2MB/s]"
          }
        },
        "4d34be021dda4e3b89f51630630f7502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78f2f1c445b145858bbb37166f1af320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dd8809a125943d4886831723e6198d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d02c3860c3694e39bf75ff7d21539f5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed80d9b5877f4c78959f0cc7023b985d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "756c1fb3559a41a68e7c8ad7ce438853": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2b59c62453f4850a1d251a2e56fff20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be766396091c4256b5f5a192760bc6ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a0025740a8547818442c4cd765da8a7",
              "IPY_MODEL_f36cfebe0f1d434cbefee62d8ab944e7",
              "IPY_MODEL_4524cec23fd54747acf8500e577e80db"
            ],
            "layout": "IPY_MODEL_6c5343aa9b4146dd92d9899f963b2154"
          }
        },
        "1a0025740a8547818442c4cd765da8a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_413da66ed56045c9bc2055c0cd2c8646",
            "placeholder": "​",
            "style": "IPY_MODEL_c75d575c0451442ba7c660593084787b",
            "value": "generation_config.json: 100%"
          }
        },
        "f36cfebe0f1d434cbefee62d8ab944e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_547cfabadd464709a4a5709ee623c735",
            "max": 242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_851b799bbfb9484da26a5005d132ba46",
            "value": 242
          }
        },
        "4524cec23fd54747acf8500e577e80db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3573ab77ab4f4336b08d90d7a5249d43",
            "placeholder": "​",
            "style": "IPY_MODEL_84c980d87b2245518bb4f606d3f5c084",
            "value": " 242/242 [00:00&lt;00:00, 21.1kB/s]"
          }
        },
        "6c5343aa9b4146dd92d9899f963b2154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "413da66ed56045c9bc2055c0cd2c8646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c75d575c0451442ba7c660593084787b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "547cfabadd464709a4a5709ee623c735": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "851b799bbfb9484da26a5005d132ba46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3573ab77ab4f4336b08d90d7a5249d43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84c980d87b2245518bb4f606d3f5c084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c9b18bce4ea4d8b8dd0c7ebc007d455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c48eb93093a442e0b49ad2645e5fa848",
              "IPY_MODEL_0ad65b10fc7d4f378f5faba49104190e",
              "IPY_MODEL_cbe43656cbac416a9babdd1e9d591181"
            ],
            "layout": "IPY_MODEL_9665192803594adca7152e71766b5080"
          }
        },
        "c48eb93093a442e0b49ad2645e5fa848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb60e5f89cea4fd1add43bf2f948d28e",
            "placeholder": "​",
            "style": "IPY_MODEL_41af8eee781c4161b3c169c893560c5c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0ad65b10fc7d4f378f5faba49104190e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0750c1cda614f8e849e689c5900f233",
            "max": 1287,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42a8fe654ac14e1694906757709ff7b3",
            "value": 1287
          }
        },
        "cbe43656cbac416a9babdd1e9d591181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1943f72a044488f80bc4b38e6b44e90",
            "placeholder": "​",
            "style": "IPY_MODEL_1f9b31fa45994cf2add81449a5d6d981",
            "value": " 1.29k/1.29k [00:00&lt;00:00, 105kB/s]"
          }
        },
        "9665192803594adca7152e71766b5080": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb60e5f89cea4fd1add43bf2f948d28e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41af8eee781c4161b3c169c893560c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0750c1cda614f8e849e689c5900f233": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42a8fe654ac14e1694906757709ff7b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1943f72a044488f80bc4b38e6b44e90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9b31fa45994cf2add81449a5d6d981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "256268b4aee7464597fbd1b82e302919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d545fb2615564304a68e4e4a7382b2aa",
              "IPY_MODEL_dbcfafa3c6b84af0b0ee5e7bcd86a7ec",
              "IPY_MODEL_06b4e8cd19734ab0b142428dc10ae938"
            ],
            "layout": "IPY_MODEL_01a5e8e2c8e14262af65a3caef023da1"
          }
        },
        "d545fb2615564304a68e4e4a7382b2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_550a9ad529f9492e82ae9e80d8d8e9d6",
            "placeholder": "​",
            "style": "IPY_MODEL_d45be867d4684ac384e16eb0efdcc3e2",
            "value": "vocab.json: 100%"
          }
        },
        "dbcfafa3c6b84af0b0ee5e7bcd86a7ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e5754c226954c65a25c2b74fd27fa53",
            "max": 2776833,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f528606d7e414dd5a48fc14ff2c92f4a",
            "value": 2776833
          }
        },
        "06b4e8cd19734ab0b142428dc10ae938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82f5c84ef8764b75b2ad40659227bb90",
            "placeholder": "​",
            "style": "IPY_MODEL_9698fb8db8f14533ac21a6a1200f2102",
            "value": " 2.78M/2.78M [00:01&lt;00:00, 1.65MB/s]"
          }
        },
        "01a5e8e2c8e14262af65a3caef023da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "550a9ad529f9492e82ae9e80d8d8e9d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d45be867d4684ac384e16eb0efdcc3e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e5754c226954c65a25c2b74fd27fa53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f528606d7e414dd5a48fc14ff2c92f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82f5c84ef8764b75b2ad40659227bb90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9698fb8db8f14533ac21a6a1200f2102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8120b65d0b824eb5be91ac180cd7d969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb20769e66c24a46bc8cdd2fa0b13638",
              "IPY_MODEL_446f1212bf2c4c0f9d69e09c40f6e9fd",
              "IPY_MODEL_ab8e447badfc4d16b65a487c3ae09dba"
            ],
            "layout": "IPY_MODEL_40e87622512b47198c397dc6b7965c5b"
          }
        },
        "bb20769e66c24a46bc8cdd2fa0b13638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed77d2e306b240788747b4028c2772e2",
            "placeholder": "​",
            "style": "IPY_MODEL_ac03d29595b5470e8270743baa318ad5",
            "value": "merges.txt: 100%"
          }
        },
        "446f1212bf2c4c0f9d69e09c40f6e9fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03b1420ad7f0466d8874d04df5f7984e",
            "max": 1671839,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_946838ed3fb34e4c9b37cd1214011d96",
            "value": 1671839
          }
        },
        "ab8e447badfc4d16b65a487c3ae09dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b400f8ff3004239883b092192903b2d",
            "placeholder": "​",
            "style": "IPY_MODEL_6df9d39d5c4c4a7f817d28481450155c",
            "value": " 1.67M/1.67M [00:00&lt;00:00, 2.34MB/s]"
          }
        },
        "40e87622512b47198c397dc6b7965c5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed77d2e306b240788747b4028c2772e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac03d29595b5470e8270743baa318ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03b1420ad7f0466d8874d04df5f7984e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "946838ed3fb34e4c9b37cd1214011d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b400f8ff3004239883b092192903b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6df9d39d5c4c4a7f817d28481450155c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "618f4130300548f9814fee86b07aa71a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae86fdcf2c5c4375bd7a876a76984e98",
              "IPY_MODEL_b09c204748744b9f89d1d928d89b424f",
              "IPY_MODEL_6455aaa7617041a6a6b8be1f1e44944a"
            ],
            "layout": "IPY_MODEL_4854f60678f0451fa6de697ff37f0565"
          }
        },
        "ae86fdcf2c5c4375bd7a876a76984e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bae935685994099bb0b776bc396ea74",
            "placeholder": "​",
            "style": "IPY_MODEL_7d72132c7a0248f5bef2fec146d73b30",
            "value": "tokenizer.json: 100%"
          }
        },
        "b09c204748744b9f89d1d928d89b424f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_571cfbe7021a4081897648c9e282a002",
            "max": 7028015,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e84d734afd846528b26a6d403887487",
            "value": 7028015
          }
        },
        "6455aaa7617041a6a6b8be1f1e44944a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0025a2d2ec054d9f94fbfa97015d98d6",
            "placeholder": "​",
            "style": "IPY_MODEL_8d5d3ccfd401460592d771eb2df56036",
            "value": " 7.03M/7.03M [00:04&lt;00:00, 1.68MB/s]"
          }
        },
        "4854f60678f0451fa6de697ff37f0565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bae935685994099bb0b776bc396ea74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d72132c7a0248f5bef2fec146d73b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "571cfbe7021a4081897648c9e282a002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e84d734afd846528b26a6d403887487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0025a2d2ec054d9f94fbfa97015d98d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d5d3ccfd401460592d771eb2df56036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QiaoLin22/MASTER-LLM-DL/blob/main/llm_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  使用 Transformer 推理模型"
      ],
      "metadata": {
        "id": "WGcETmzJN5vI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "domZVKFKN6RQ",
        "outputId": "4b6038cc-ae42-464e-fc89-8e3b46e6f985"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.26.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "device = \"cuda\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Qwen/Qwen1.5-1.8B-Chat\",\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-1.8B-Chat\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348,
          "referenced_widgets": [
            "c22b8879f4b34e4a8dd420d68cfdd797",
            "f72d6f70943245c4b2411c6adefbeb10",
            "151afb38ddb84602ba3a030dcd61a84b",
            "699d6b5ffbd043ad8822920efb13a1d7",
            "de7fc063687044b7a8d20c2270cc95ae",
            "fb5548eb5b59430ba3e83410caedef4d",
            "d6c89a14276a437285a3ad38cbc49fcb",
            "9a70302754294cc39f027fba871e2aca",
            "2da57fb2cec8429fab0c7d49374cd2ea",
            "88f963333c514e3d947d735feaa95278",
            "1ae4403751dd40d79872c2e7d2ae0758",
            "57c31afee6c944ccb38b4a2f268f7d3d",
            "622926d04e164f6a9f4f96b8acaa00c9",
            "1665b37ad6774f4ca01099a4c36c1c7a",
            "c42d93dca83345e1ae62d1b6e7ebf990",
            "6a43ef5b29f84181905c1559ba0ef19e",
            "12473150cfca47fd8d8b1eee6b926e1b",
            "7f5fa96b9b7f4d3585a6081500c10d07",
            "095152560d974eb29ad9c5013d99d3cb",
            "bc2bd98c532e4c15bf6cf0138bbfce24",
            "c1c3a584eec3460aa4809b2d7bc73829",
            "e8a1ad3e26a3411f858b996fe6024e4f",
            "ff60733f9a3845ad86acae85023cdf9b",
            "4e9dbee5127541f7a3c83988da51bf86",
            "600d8c7ac0dc4fa7880879acf4b2a690",
            "8ad8b98039c449499f9cb475734219e5",
            "60e200fefb2b4bba8f9ed5e9053b9c0f",
            "086a055c92e1484896e632f1c9733b5c",
            "a3b86b7c2a5c48e8a5a62a564d93ddf5",
            "c950f3e085814bfe9027e4bc501e4d61",
            "f741886996a846888316683d5d3795ba",
            "57f42deb21a64537a5bd33f4c9c56d8a",
            "bbc7e33aa40e402d8323c6ab65fbf27e",
            "7c1fe4cb4dba404a83d42ac8f38d53d4",
            "fb2b0688844d4165b518d35b6a6e6e56",
            "e42c582e67ec41438f84959798557021",
            "b21d44e333f0441985deec7db1983fc8",
            "f07bb9874b764072a5a910ac332f203c",
            "e7dc1f5422de4f68935e8cde34204ed2",
            "b1def8b2760142229bd1f25fe3aedcc2",
            "70a53574cf5d4061aebcff0e3a171b0f",
            "d982e5e2ad9b4b4f928b8ebb0390593e",
            "7962de74990341f3a3f4e8f37681080f",
            "21d3b8e22303490ebc726d93f41908fc",
            "00f083e314bb48c1abdc1303a1a4cfa2",
            "7972f6ea86e24b98bffa63100dda9cfd",
            "5da4616f04ec4e1a8f405e0bab02f54f",
            "06ece4f0bc264d92af1bfb7977bd9342",
            "8d74cbfe37e14cffae4cb088dffac302",
            "1e60f3ec6a674c5bb5dbb552a12f8321",
            "40053ed145064565a872cafae44ed0b0",
            "b37a35b3b9be441693553d07b77edb2b",
            "35ad1399dd1541d787cec6da6bdf0602",
            "0a46e05f8c9949d1a985374a977f0d74",
            "75911f77f1e4498e9c2d7a91a763d443",
            "59c02d321c5243a8899d0ed866d291c2",
            "139371307dd24d1eb31c77c69a89c21c",
            "62818bcb8d6a4d3f9f97a97b01051e87",
            "5ff80a3cbb0340af93689371f97806f6",
            "b02b16e43956420183df2463b3252dff",
            "b547701d154c40c48c7f2053068e894c",
            "3871290960404eafb6028aebe8cadee3",
            "2c76985c4b6545b1a460a1658ce6f93d",
            "a05f77ca05374d04838af44941280587",
            "9092f67331f94be089dca31c9f2e3cf4",
            "cedb15bb75964e888b12b8ec17c823b2",
            "2fd7cf4ff9ee4cfba76a9eafb0abf188",
            "782a340fa8dc4aeba2de54b9ef950d80",
            "4c6ffc30e18c43b3997dff47dceea3b5",
            "e506000cfdf84f8a98f50fb7cca9cf20",
            "6b1d930621bd4a36a1c0ed0474933e3d",
            "2fb80e28acc64df3bafa8c13d07896ff",
            "f58de4207b59454d983d94ec3656e2c0",
            "d95d70ae903f4a71ab86e6d1c63e32bf",
            "a917bdab57ff4d9caba689c115a49316",
            "9e1a4127e4404cf3834d0e392567e911",
            "2ec9441391c740d588c9b37cec35e6f3"
          ]
        },
        "id": "nRmMcY9_OBO_",
        "outputId": "ff2a9fe9-8ad5-4301-9784-91563979b2ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c22b8879f4b34e4a8dd420d68cfdd797"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57c31afee6c944ccb38b4a2f268f7d3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/206 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff60733f9a3845ad86acae85023cdf9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c1fe4cb4dba404a83d42ac8f38d53d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00f083e314bb48c1abdc1303a1a4cfa2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59c02d321c5243a8899d0ed866d291c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2fd7cf4ff9ee4cfba76a9eafb0abf188"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Give me a short introduction to large language model.\"\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "print(\"模板化后：\"+text)\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "print(model_inputs.input_ids)\n",
        "# Directly use generate() and tokenizer.decode() to get the output.\n",
        "# Use `max_new_tokens` to control the maximum output length.\n",
        "generated_ids = model.generate(\n",
        "    model_inputs.input_ids,\n",
        "    max_new_tokens=512\n",
        ")\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "print(\"========================================================================\")\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "print(response)"
      ],
      "metadata": {
        "id": "P84g66TSTQHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67971030-d953-442d-e351-589e41becc1e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "模板化后：<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>user\n",
            "Give me a short introduction to large language model.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n",
            "tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n",
            "         151645,    198, 151644,    872,    198,  35127,    752,    264,   2805,\n",
            "          16800,    311,   3460,   4128,   1614,     13, 151645,    198, 151644,\n",
            "          77091,    198]], device='cuda:0')\n",
            "========================================================================\n",
            "\n",
            "\n",
            "Large Language Models (LLMs) are artificial intelligence models that are capable of processing and generating human-like text, speech, or other forms of natural language. These models are designed to learn from vast amounts of text data, such as books, articles, news articles, social media posts, and more, and use this knowledge to generate text that is coherent, informative, and contextually relevant.\n",
            "\n",
            "There are several types of LLMs, including:\n",
            "\n",
            "1. Recurrent Neural Networks (RNNs): RNNs are a type of neural network that can process sequences of inputs, such as sentences or paragraphs, by using the past input values to predict the next one. They have been successful in generating long-form text, such as novels, poetry, and scientific papers.\n",
            "\n",
            "2. Transformer Models: The transformer architecture is a type of RNN that has revolutionized the field of NLP by allowing for self-attention mechanisms, which enable the model to focus on different parts of the input sequence while attending to distant neighbors. This allows the model to capture complex dependencies between words and phrases, making it well-suited for tasks like machine translation, summarization, and question answering.\n",
            "\n",
            "3. GPT-3: Google's Generative Pre-trained Transformer Model (GPT-3) is a state-of-the-art LLM that has achieved human-level performance in various natural language generation tasks. It consists of three main components: an encoder, a decoder, and a fine-tuning process. The encoder generates a low-dimensional representation of the input text, while the decoder uses this representation to generate the final output text. GPT-3 can generate text in multiple languages and has demonstrated impressive abilities in tasks such as language translation, text generation, and text completion.\n",
            "\n",
            "4. BERT: TheBidirectional Encoder Representations from Transformers (BERT) is a pre-trained model developed by Google that has shown remarkable success in various NLP tasks, including language understanding, text classification, and named entity recognition. It consists of two main submodels: the left-side encoder and the right-side encoder, which take as input a sequence of tokens and encode them into dense representations using both forward and backward passes. BERT has outperformed previous state-of-the-art models in many benchmarks, particularly in the context of conversational AI.\n",
            "\n",
            "5. OpenAI GPT-3: An open-source version of GPT-3 called OpenAI's GPT-3 Large Pretrained Transformer (GPT-3-LP) was released in 2022 and has since\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "device = \"cuda\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Qwen/Qwen2-0.5B-Instruct\",\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")"
      ],
      "metadata": {
        "id": "PPyuH7GRTT7N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "d11564dceb294fb9813b3e1646a29bd2",
            "b1e8f82636904bd5ab8902df05c8bf6b",
            "f4521dc78ed845d78c677c4d65359be5",
            "e3433fa7602c486f84a7667416e85fd1",
            "79d300d1241547e38e39546339a97119",
            "7301a847922940688c4015fcf734cf37",
            "0537087ee0a54a878243bb3f18d6b28d",
            "cad4ab7878884b3bba21dc6591477518",
            "9863390b0f384af8bfcd6423c98c985b",
            "551607401df447c29e9010feb3ca3ef9",
            "06fe437bd74b4b29af233dcc52da8df3",
            "11ab7e1ce6fd4fb394a68bb5f92ccc38",
            "47fc2fef5bb0457ca1d4b4cb48b4f166",
            "82777cb8f33941888966fd52052590ff",
            "5b42332c54304e6b9975f6f176b51b55",
            "4d34be021dda4e3b89f51630630f7502",
            "78f2f1c445b145858bbb37166f1af320",
            "6dd8809a125943d4886831723e6198d5",
            "d02c3860c3694e39bf75ff7d21539f5d",
            "ed80d9b5877f4c78959f0cc7023b985d",
            "756c1fb3559a41a68e7c8ad7ce438853",
            "c2b59c62453f4850a1d251a2e56fff20",
            "be766396091c4256b5f5a192760bc6ac",
            "1a0025740a8547818442c4cd765da8a7",
            "f36cfebe0f1d434cbefee62d8ab944e7",
            "4524cec23fd54747acf8500e577e80db",
            "6c5343aa9b4146dd92d9899f963b2154",
            "413da66ed56045c9bc2055c0cd2c8646",
            "c75d575c0451442ba7c660593084787b",
            "547cfabadd464709a4a5709ee623c735",
            "851b799bbfb9484da26a5005d132ba46",
            "3573ab77ab4f4336b08d90d7a5249d43",
            "84c980d87b2245518bb4f606d3f5c084",
            "1c9b18bce4ea4d8b8dd0c7ebc007d455",
            "c48eb93093a442e0b49ad2645e5fa848",
            "0ad65b10fc7d4f378f5faba49104190e",
            "cbe43656cbac416a9babdd1e9d591181",
            "9665192803594adca7152e71766b5080",
            "bb60e5f89cea4fd1add43bf2f948d28e",
            "41af8eee781c4161b3c169c893560c5c",
            "e0750c1cda614f8e849e689c5900f233",
            "42a8fe654ac14e1694906757709ff7b3",
            "e1943f72a044488f80bc4b38e6b44e90",
            "1f9b31fa45994cf2add81449a5d6d981",
            "256268b4aee7464597fbd1b82e302919",
            "d545fb2615564304a68e4e4a7382b2aa",
            "dbcfafa3c6b84af0b0ee5e7bcd86a7ec",
            "06b4e8cd19734ab0b142428dc10ae938",
            "01a5e8e2c8e14262af65a3caef023da1",
            "550a9ad529f9492e82ae9e80d8d8e9d6",
            "d45be867d4684ac384e16eb0efdcc3e2",
            "9e5754c226954c65a25c2b74fd27fa53",
            "f528606d7e414dd5a48fc14ff2c92f4a",
            "82f5c84ef8764b75b2ad40659227bb90",
            "9698fb8db8f14533ac21a6a1200f2102",
            "8120b65d0b824eb5be91ac180cd7d969",
            "bb20769e66c24a46bc8cdd2fa0b13638",
            "446f1212bf2c4c0f9d69e09c40f6e9fd",
            "ab8e447badfc4d16b65a487c3ae09dba",
            "40e87622512b47198c397dc6b7965c5b",
            "ed77d2e306b240788747b4028c2772e2",
            "ac03d29595b5470e8270743baa318ad5",
            "03b1420ad7f0466d8874d04df5f7984e",
            "946838ed3fb34e4c9b37cd1214011d96",
            "1b400f8ff3004239883b092192903b2d",
            "6df9d39d5c4c4a7f817d28481450155c",
            "618f4130300548f9814fee86b07aa71a",
            "ae86fdcf2c5c4375bd7a876a76984e98",
            "b09c204748744b9f89d1d928d89b424f",
            "6455aaa7617041a6a6b8be1f1e44944a",
            "4854f60678f0451fa6de697ff37f0565",
            "1bae935685994099bb0b776bc396ea74",
            "7d72132c7a0248f5bef2fec146d73b30",
            "571cfbe7021a4081897648c9e282a002",
            "8e84d734afd846528b26a6d403887487",
            "0025a2d2ec054d9f94fbfa97015d98d6",
            "8d5d3ccfd401460592d771eb2df56036"
          ]
        },
        "outputId": "ccd3c9b3-8fe3-4175-e09d-293dcbe53d2c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d11564dceb294fb9813b3e1646a29bd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11ab7e1ce6fd4fb394a68bb5f92ccc38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be766396091c4256b5f5a192760bc6ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c9b18bce4ea4d8b8dd0c7ebc007d455"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "256268b4aee7464597fbd1b82e302919"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8120b65d0b824eb5be91ac180cd7d969"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "618f4130300548f9814fee86b07aa71a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of using model.chat(), we directly use model.generate()\n",
        "# But you need to use tokenizer.apply_chat_template() to format your inputs as shown below\n",
        "prompt = \"Give me a short introduction to large language model.\"\n",
        "messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"你好，我叫蔡徐坤。今天天气如何\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"你好，很高兴认识你，今天是晴天哦\"},\n",
        "        {\"role\": \"user\", \"content\": \"好的，那我今天要吃什么呢？\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"好天气，建议多吃瓜果蔬菜，保持健康\"},\n",
        "        {\"role\": \"user\", \"content\": \"谢谢你的意见，你知道蔡徐坤是谁吗？\"},\n",
        "    ]\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "print(\"模板化后：\"+text)\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "print(model_inputs.input_ids)\n",
        "# Directly use generate() and tokenizer.decode() to get the output.\n",
        "# Use `max_new_tokens` to control the maximum output length.\n",
        "generated_ids = model.generate(\n",
        "    model_inputs.input_ids,\n",
        "    max_new_tokens=512\n",
        ")\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "print(\"========================================================================\")\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "print(response)"
      ],
      "metadata": {
        "id": "ZLK-uG9CTYkU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "665d5363-81be-4687-e372-13a381ade6bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "模板化后：<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>user\n",
            "你好，我叫蔡徐坤。今天天气如何<|im_end|>\n",
            "<|im_start|>assistant\n",
            "你好，很高兴认识你，今天是晴天哦<|im_end|>\n",
            "<|im_start|>user\n",
            "好的，那我今天要吃什么呢？<|im_end|>\n",
            "<|im_start|>assistant\n",
            "好天气，建议多吃瓜果蔬菜，保持健康<|im_end|>\n",
            "<|im_start|>user\n",
            "谢谢你的意见，你知道蔡徐坤是谁吗？<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n",
            "tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n",
            "         151645,    198, 151644,    872,    198, 108386,   3837,  35946,  99882,\n",
            "         104676, 101957, 102954,   1773, 100644, 104307, 100007, 151645,    198,\n",
            "         151644,  77091,    198, 108386,   3837, 112169, 100720,  56568,   3837,\n",
            "         100644,  20412, 105212,  35727, 104170, 151645,    198, 151644,    872,\n",
            "            198,  99692,   3837,  99212,  35946, 100644,  30534,  99405, 111383,\n",
            "          11319, 151645,    198, 151644,  77091,    198,  52801, 104307,   3837,\n",
            "         101898, 108851, 100857,  27773, 104451,   3837, 100662,  99722, 151645,\n",
            "            198, 151644,    872,    198, 102570, 103929, 100065,   3837, 107733,\n",
            "         104676, 101957, 102954, 105518, 101037,  11319, 151645,    198, 151644,\n",
            "          77091,    198]], device='cuda:0')\n",
            "========================================================================\n",
            "蔡徐坤是湖南长沙人，中国流行音乐、影视演员、歌手，曾获得第34届金曲奖最佳男歌手奖，2018年凭借《偶像练习生》出道，随后发行多张专辑并参与电影拍摄和演出。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 使用 VLLM 推理"
      ],
      "metadata": {
        "id": "pIkUF3mrTZRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vllm\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wbzh__Q9TbrX",
        "outputId": "7a734eb8-ab94-4b0d-a8fc-4e5f76cf8751"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vllm in /usr/local/lib/python3.10/dist-packages (0.6.3.post1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vllm) (4.66.6)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from vllm) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.45.2 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.46.2)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.20.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from vllm) (4.25.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from vllm) (3.10.10)\n",
            "Requirement already satisfied: openai>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.54.3)\n",
            "Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.10/dist-packages (from vllm) (0.32.0)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.9.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from vllm) (10.4.0)\n",
            "Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.21.0)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (7.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.7.0)\n",
            "Requirement already satisfied: lm-format-enforcer==0.10.6 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.10.6)\n",
            "Requirement already satisfied: outlines<0.1,>=0.0.43 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.0.46)\n",
            "Requirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.12.2)\n",
            "Requirement already satisfied: filelock>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from vllm) (3.16.1)\n",
            "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.10/dist-packages (from vllm) (0.2.1.1.post4)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from vllm) (24.0.1)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.10/dist-packages (from vllm) (0.18.6)\n",
            "Requirement already satisfied: gguf==0.10.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.10.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from vllm) (8.5.0)\n",
            "Requirement already satisfied: mistral-common>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from mistral-common[opencv]>=1.4.4->vllm) (1.4.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from vllm) (6.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from vllm) (0.8.0)\n",
            "Requirement already satisfied: compressed-tensors==0.6.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.6.0)\n",
            "Requirement already satisfied: ray>=2.9 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.39.0)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.10/dist-packages (from vllm) (12.560.30)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.4.0)\n",
            "Requirement already satisfied: torchvision==0.19 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.19.0)\n",
            "Requirement already satisfied: xformers==0.0.27.post2 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.0.27.post2)\n",
            "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.115.5)\n",
            "Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer==0.10.6->vllm) (0.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer==0.10.6->vllm) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->vllm) (12.6.77)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm) (0.41.2)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.21.1 in /usr/local/lib/python3.10/dist-packages (from mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm) (4.23.0)\n",
            "Requirement already satisfied: opencv-python-headless<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mistral-common[opencv]>=1.4.4->vllm) (4.10.0.84)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (0.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (1.3.1)\n",
            "Requirement already satisfied: lark in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (1.2.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (1.6.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (3.1.0)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (5.6.3)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (0.60.0)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (0.35.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (3.1.0)\n",
            "Requirement already satisfied: pycountry in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (24.6.1)\n",
            "Requirement already satisfied: pyairports in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (2.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9->vllm) (2.23.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (8.1.7)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.1.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (2024.8.30)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.6.0->vllm) (2024.9.11)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.19.1->vllm) (0.26.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.45.2->vllm) (0.4.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (2.4.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (24.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (4.0.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->vllm) (3.20.2)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (14.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.40.0->vllm) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.40.0->vllm) (1.0.6)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm) (2024.10.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm) (0.21.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->vllm) (0.2.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (0.70.16)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->vllm) (3.0.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->outlines<0.1,>=0.0.43->vllm) (0.43.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->vllm) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->outlines<0.1,>=0.0.43->vllm) (1.16.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 后台启动模仿 openAI api 的服务\n",
        "!nohup python -m vllm.entrypoints.openai.api_server --model Qwen/Qwen1.5-1.8B-Chat  --dtype half  --gpu-memory-utilization 0.95 --max-model-len 2048 &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z64pLj-3Tio4",
        "outputId": "9cc07ce8-0b94-4628-8429-2d727b3bc2a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat  nohup.out"
      ],
      "metadata": {
        "id": "x8lbubGiY8w5",
        "outputId": "8364258f-1a95-41df-88ae-cd1a82867a0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-13 17:50:46.810784: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-13 17:50:46.827063: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-13 17:50:46.848594: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-13 17:50:46.855023: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-13 17:50:46.870111: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-13 17:50:48.051770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO 11-13 17:50:51 api_server.py:528] vLLM API server version 0.6.3.post1\n",
            "INFO 11-13 17:50:51 api_server.py:529] args: Namespace(host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='Qwen/Qwen1.5-1.8B-Chat', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='half', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=2048, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, disable_sliding_window=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.95, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, enforce_eager=False, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, scheduling_policy='fcfs', disable_log_requests=False, max_log_len=None, disable_fastapi_docs=False)\n",
            "INFO 11-13 17:50:51 api_server.py:166] Multiprocessing frontend to use ipc:///tmp/b6b3f7bd-2e47-4bb5-beff-1c5915c9fb6d for IPC Path.\n",
            "INFO 11-13 17:50:51 api_server.py:179] Started engine process with PID 18582\n",
            "WARNING 11-13 17:50:52 config.py:1668] Casting torch.bfloat16 to torch.float16.\n",
            "2024-11-13 17:50:55.537765: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-13 17:50:55.558611: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-13 17:50:55.564894: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-13 17:50:56.752072: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING 11-13 17:51:00 config.py:1668] Casting torch.bfloat16 to torch.float16.\n",
            "WARNING 11-13 17:51:01 arg_utils.py:1019] [DEPRECATED] Block manager v1 has been removed, and setting --use-v2-block-manager to True or False has no effect on vLLM behavior. Please remove --use-v2-block-manager in your engine argument. If your use case is not supported by SelfAttnBlockSpaceManager (i.e. block manager v2), please file an issue with detailed information.\n",
            "WARNING 11-13 17:51:08 arg_utils.py:1019] [DEPRECATED] Block manager v1 has been removed, and setting --use-v2-block-manager to True or False has no effect on vLLM behavior. Please remove --use-v2-block-manager in your engine argument. If your use case is not supported by SelfAttnBlockSpaceManager (i.e. block manager v2), please file an issue with detailed information.\n",
            "INFO 11-13 17:51:08 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='Qwen/Qwen1.5-1.8B-Chat', speculative_config=None, tokenizer='Qwen/Qwen1.5-1.8B-Chat', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen1.5-1.8B-Chat, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=True, mm_processor_kwargs=None)\n",
            "INFO 11-13 17:51:10 model_runner.py:1056] Starting to load model Qwen/Qwen1.5-1.8B-Chat...\n",
            "INFO 11-13 17:51:11 weight_utils.py:243] Using model weights format ['*.safetensors']\n",
            "INFO 11-13 17:51:11 weight_utils.py:288] No model.safetensors.index.json found in remote.\n",
            "\rLoading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "\rLoading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.42s/it]\n",
            "\rLoading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.42s/it]\n",
            "\n",
            "INFO 11-13 17:51:13 model_runner.py:1067] Loading model weights took 3.4653 GB\n",
            "INFO 11-13 17:51:14 gpu_executor.py:122] # GPU blocks: 11087, # CPU blocks: 1365\n",
            "INFO 11-13 17:51:14 gpu_executor.py:126] Maximum concurrency for 2048 tokens per request: 86.62x\n",
            "INFO 11-13 17:51:17 model_runner.py:1395] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
            "INFO 11-13 17:51:17 model_runner.py:1399] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
            "INFO 11-13 17:51:38 model_runner.py:1523] Graph capturing finished in 21 secs.\n",
            "INFO 11-13 17:51:38 api_server.py:232] vLLM to use /tmp/tmpb7xks5dw as PROMETHEUS_MULTIPROC_DIR\n",
            "WARNING 11-13 17:51:38 serving_embedding.py:199] embedding_mode is False. Embedding API will not work.\n",
            "INFO 11-13 17:51:38 launcher.py:19] Available routes are:\n",
            "INFO 11-13 17:51:38 launcher.py:27] Route: /openapi.json, Methods: GET, HEAD\n",
            "INFO 11-13 17:51:38 launcher.py:27] Route: /docs, Methods: GET, HEAD\n",
            "INFO 11-13 17:51:38 launcher.py:27] Route: /docs/oauth2-redirect, Methods: GET, HEAD\n",
            "INFO 11-13 17:51:38 launcher.py:27] Route: /redoc, Methods: GET, HEAD\n",
            "INFO 11-13 17:51:38 launcher.py:27] Route: /health, Methods: GET\n",
            "INFO 11-13 17:51:38 launcher.py:27] Route: /tokenize, Methods: POST\n",
            "INFO 11-13 17:51:38 launcher.py:27] Route: /detokenize, Methods: POST\n",
            "INFO 11-13 17:51:38 launcher.py:27] Route: /v1/models, Methods: GET\n",
            "INFO 11-13 17:51:38 launcher.py:27] Route: /version, Methods: GET\n",
            "INFO 11-13 17:51:38 launcher.py:27] Route: /v1/chat/completions, Methods: POST\n",
            "INFO 11-13 17:51:38 launcher.py:27] Route: /v1/completions, Methods: POST\n",
            "INFO 11-13 17:51:38 launcher.py:27] Route: /v1/embeddings, Methods: POST\n",
            "INFO:     Started server process [18496]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on socket ('0.0.0.0', 8000) (Press CTRL+C to quit)\n",
            "INFO 11-13 17:51:48 metrics.py:349] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.\n",
            "INFO 11-13 17:51:58 metrics.py:349] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.\n",
            "2024-11-13 17:52:00.644002: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-13 17:52:00.659945: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-13 17:52:00.681045: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-13 17:52:00.687428: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-13 17:52:00.702233: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "# Set OpenAI's API key and API base to use vLLM's API server.\n",
        "openai_api_key = \"EMPTY\"\n",
        "openai_api_base = \"http://localhost:8000/v1\"\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=openai_api_key,\n",
        "    base_url=openai_api_base,\n",
        ")\n",
        "\n",
        "chat_response = client.chat.completions.create(\n",
        "    model=\"Qwen/Qwen1.5-1.8B-Chat\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Tell me something about large language models.\"},\n",
        "    ]\n",
        ")\n",
        "print(\"Chat response:\", chat_response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVhS4aOSplfS",
        "outputId": "f9f49472-4f5a-4169-9114-ec8dfe7c7da5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chat response: Large language models (LLMs) are artificial intelligence models that have been developed with the ability to generate human-like text on a wide range of topics. These models are typically trained using a combination of statistical and neural network techniques, and their ability to produce text has led to significant advancements in natural language processing and language generation.\n",
            "\n",
            "The basic architecture of an LLM includes two main components: a large corpus of text data (the \"training data\") and a deep neural network architecture that is trained on this data to learn patterns and relationships between words and phrases. The training data consists of a vast corpus of text, such as books, articles, or web pages, that has been manually labeled with the appropriate sentences or phrases. The LLM is trained on this data by minimizing a loss function that measures the difference between the predicted output and the actual output.\n",
            "\n",
            "During training, the LLM is exposed to a gradually increasing sequence of input data, called the \"prompt,\" which specifies the desired output. The model uses its large vocabulary to predict the most likely sequence of words that would generate the desired output, based on the patterns it has learned from the training data. Over time, the model learns to generate more complex and varied text that is increasingly similar to the original training data.\n",
            "\n",
            "One of the key advantages of LLMs is their ability to generate text at scale. With the vast amounts of text data available, LLMs can generate vast amounts of text quickly and efficiently, which can be useful for a wide range of applications, including generating product descriptions, news articles, chatbot responses, and even creative writing.\n",
            "\n",
            "LLMs have also shown impressive capabilities in various natural language tasks, such as language translation, question answering, summarization, and text generation. For example, a popular example of an LLM is the GPT-3, which has been trained on a massive corpus of text and is capable of generating coherent and human-like text on a wide range of topics.\n",
            "\n",
            "Despite their many benefits, LLMs also have some limitations and challenges. One of the primary challenges is the ability to generate text that is truly human-like, with the ability to express nuance, humor, and emotion. While some LLMs have achieved impressive results in generating text that can mimic human language, there are still significant gaps in the quality and consistency of this output, particularly when it comes to idiomatic expressions, sarcasm, or humor.\n",
            "\n",
            "Another challenge is the privacy and ethical implications of large language models. As LLMs generate vast amounts of text data, there is a risk of identifying individuals or groups based on the words and phrases they generate, which could raise concerns about privacy and surveillance. Additionally, there are concerns about the potential for LLMs to be used for malicious purposes, such as generating fake news or propaganda.\n",
            "\n",
            "Despite these challenges, LLMs continue to advance rapidly, and their potential applications are vast. As the technology continues to evolve, we can expect to see even more sophisticated and advanced LLMs that are able to generate more sophisticated and nuanced text, as well as addressing some of the challenges and limitations of the current models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# llama.cpp 推理"
      ],
      "metadata": {
        "id": "IRaFh0h0qtwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ggerganov/llama.cpp\n",
        "%cd llama.cpp\n",
        "# CPU编译\n",
        "#!make\n",
        "# CUDA编译\n",
        "# !make GGML_CUDA=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJBShxa0qumH",
        "outputId": "002aebee-0b23-4bfc-e015-15948afd70ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 37380, done.\u001b[K\n",
            "remote: Counting objects: 100% (9375/9375), done.\u001b[K\n",
            "remote: Compressing objects: 100% (858/858), done.\u001b[K\n",
            "remote: Total 37380 (delta 8941), reused 8765 (delta 8513), pack-reused 28005 (from 1)\u001b[K\n",
            "Receiving objects: 100% (37380/37380), 59.23 MiB | 15.78 MiB/s, done.\n",
            "Resolving deltas: 100% (27278/27278), done.\n",
            "/content/llama.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# 安装 brew\n",
        "sudo apt-get update >/dev/null\n",
        "sudo apt-get install build-essential procps curl file git >/dev/null 2>&1\n",
        "\n",
        "# Homebrew\n",
        "/bin/bash -c \\\n",
        "  \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" \\\n",
        "  >/dev/null 2>&1\n",
        "/home/linuxbrew/.linuxbrew/bin/brew -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoqTnWK0rNjn",
        "outputId": "8bf40266-8f30-4bc4-efe5-a321db575f49"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Homebrew 4.4.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "/home/linuxbrew/.linuxbrew/bin/brew install llama.cpp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wiama2vrVMc",
        "outputId": "6e4e61b2-3a15-47bc-ff20-1654fc4d0341"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Downloading https://ghcr.io/v2/homebrew/core/llama.cpp/manifests/4071\n",
            "==> Fetching dependencies for llama.cpp: gmp, isl, mpfr, libmpc, lz4, xz, zlib, zstd, binutils, gcc, openblas, brotli, libnghttp2, ca-certificates, openssl@3, libssh2, rtmpdump, libunistring, libidn2, ncurses, libedit, krb5, readline, libxcrypt, sqlite, util-linux, openldap and curl\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/gmp/manifests/6.3.0\n",
            "==> Fetching gmp\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/gmp/blobs/sha256:3dca3544faca889c7389a5fdbd2b5b00582c34a4e14607033573ad3b06ca7882\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/isl/manifests/0.27\n",
            "==> Fetching isl\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/isl/blobs/sha256:25c8bf618d4e3c68c27eed634bd7695104ff5daa37246253aabce80d7c1ac7f5\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/mpfr/manifests/4.2.1\n",
            "==> Fetching mpfr\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/mpfr/blobs/sha256:18857bac44d9f49faeb1d147146ba7fb420d5bf85076f69c68a86a563b203c13\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libmpc/manifests/1.3.1\n",
            "==> Fetching libmpc\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libmpc/blobs/sha256:f6542ae5bcf643ca0c980c7000cde1585922e76be080b3cc3422dac0d4a50904\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/lz4/manifests/1.10.0-1\n",
            "==> Fetching lz4\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/lz4/blobs/sha256:a8082c2e40dc6d63850f43ea8fa095e55adf18fb0f25ec66bcaee2c4b4438205\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/xz/manifests/5.6.3\n",
            "==> Fetching xz\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/xz/blobs/sha256:360e9e63603136e0a4af1c9d0a6c28429fca9008fa5210cc12c2934117223c39\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/zlib/manifests/1.3.1\n",
            "==> Fetching zlib\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/zlib/blobs/sha256:38f2469db2ce63b70855a98e5ee27b5b5a92874e52542cbdc0b230bba1e7195f\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/zstd/manifests/1.5.6\n",
            "==> Fetching zstd\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/zstd/blobs/sha256:0e6ddbd4c969bb84261f12b759fb78a828d6f734c9e515793c6ac2c3a846b01e\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/binutils/manifests/2.43.1\n",
            "==> Fetching binutils\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/binutils/blobs/sha256:ab5913dd80970340737b8450c3d227f2e6ad07874c240a82d1749ff4bba8b863\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/gcc/manifests/14.2.0_1\n",
            "==> Fetching gcc\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/gcc/blobs/sha256:0902085b2185b224dd20c2ee5f12d83284cdbb68d0dab1e2edbd4c6603545de6\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/openblas/manifests/0.3.28\n",
            "==> Fetching openblas\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/openblas/blobs/sha256:9ac6e26f577d71f531bd0f268616ad2aa845c3c2843154b6206e7a293f017100\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/brotli/manifests/1.1.0-1\n",
            "==> Fetching brotli\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/brotli/blobs/sha256:5a2e1cc12312a092b38e79952fd2232f564f2c64cda0f69e97a55c65df9b29ab\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libnghttp2/manifests/1.64.0\n",
            "==> Fetching libnghttp2\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libnghttp2/blobs/sha256:8b4c922766aa304a0f749d7f9c019cd77f9706ac65ce0223857f60c68760319f\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/ca-certificates/manifests/2024-09-24\n",
            "==> Fetching ca-certificates\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/ca-certificates/blobs/sha256:212f2576348d5f5797d8d3905eb70d0d9bf8829345bce9e20e2fd0336f344648\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/openssl/3/manifests/3.4.0\n",
            "==> Fetching openssl@3\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/openssl/3/blobs/sha256:424afb56cdd116602c373db5ff55fbaef0865775cfacdc18c5e6a71aa24845e9\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libssh2/manifests/1.11.1\n",
            "==> Fetching libssh2\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libssh2/blobs/sha256:a307208b03d0761f7ea8c53a322ea09b0a60db96e3ef8688df6adec92b45ca5b\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/rtmpdump/manifests/2.4-20151223_3\n",
            "==> Fetching rtmpdump\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/rtmpdump/blobs/sha256:0ab7f054fd0b01975be1893437235c61e2761ed9fb54e7880a854ca37809d57e\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libunistring/manifests/1.3\n",
            "==> Fetching libunistring\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libunistring/blobs/sha256:25ff65379463fe4a51008a36c45a963ebc8d13d054ce606e3fbb6635ea634311\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libidn2/manifests/2.3.7\n",
            "==> Fetching libidn2\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libidn2/blobs/sha256:2d94c867e00156a44644758c62895dd6d13538aff7f638ea598ff70e0e8f6505\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/ncurses/manifests/6.5\n",
            "==> Fetching ncurses\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/ncurses/blobs/sha256:7c49662d0f319baec24475d38210b2f9c754b2ec1d21a4a3ff39ce81d8605f03\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libedit/manifests/20240808-3.1\n",
            "==> Fetching libedit\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libedit/blobs/sha256:8e574e7c9d236e3c6d12b208934ebe3159e27b50bfd700f73fad765b67ce86e8\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/krb5/manifests/1.21.3\n",
            "==> Fetching krb5\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/krb5/blobs/sha256:f5b4cafedb315e92a31a0a5d87e33f7826952bcc5c093ba65817c61247799601\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/readline/manifests/8.2.13\n",
            "==> Fetching readline\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/readline/blobs/sha256:099378b496dd58f6a0fdb09e4c32d2ccae5631c0b423c1df77626d844553a85f\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libxcrypt/manifests/4.4.36\n",
            "==> Fetching libxcrypt\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libxcrypt/blobs/sha256:ad1c4b570d7a66046038c13345b54337d858a2db78dcfb7e90a2b21adc1d6802\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/sqlite/manifests/3.47.0\n",
            "==> Fetching sqlite\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/sqlite/blobs/sha256:876ee5b13d16e4147a7ed7df891037188dba92d016d3aeb922eb785bd2f5a816\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/util-linux/manifests/2.40.2-1\n",
            "==> Fetching util-linux\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/util-linux/blobs/sha256:773c91eea7c86a3a5a18ae1b43a43c9346b190ccf7640bb811e4cadb77a42874\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/openldap/manifests/2.6.8\n",
            "==> Fetching openldap\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/openldap/blobs/sha256:8b49f676a7948a38bdc1b8089400628c95502330a0d2569635d4741bce3d1e53\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/curl/manifests/8.11.0_1-1\n",
            "==> Fetching curl\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/curl/blobs/sha256:48c94b796c1615b3695ebea3b95b8f40168697e80122ca4f1266e410d3eca91c\n",
            "==> Fetching llama.cpp\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/llama.cpp/blobs/sha256:6737ed10c0ba735af3d21fbc1a448f81adac33b74d87bdd6daaf7d4a031a72df\n",
            "==> Installing dependencies for llama.cpp: gmp, isl, mpfr, libmpc, lz4, xz, zlib, zstd, binutils, gcc, openblas, brotli, libnghttp2, ca-certificates, openssl@3, libssh2, rtmpdump, libunistring, libidn2, ncurses, libedit, krb5, readline, libxcrypt, sqlite, util-linux, openldap and curl\n",
            "==> Installing llama.cpp dependency: gmp\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/gmp/manifests/6.3.0\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/70a72a71216843d66a953c06ff6337445ce9bc94fae9f0e301e2f59005274a8e--gmp-6.3.0.bottle_manifest.json\n",
            "==> Pouring gmp--6.3.0.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/gmp/6.3.0: 24 files, 3.9MB\n",
            "==> Installing llama.cpp dependency: isl\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/isl/manifests/0.27\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/40b1c5526f95db33208143fa79887179e758121659d8877597f553e6e6188879--isl-0.27.bottle_manifest.json\n",
            "==> Pouring isl--0.27.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/isl/0.27: 75 files, 9.9MB\n",
            "==> Installing llama.cpp dependency: mpfr\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/mpfr/manifests/4.2.1\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/a2a3424f4974f6febfa0334a93f35f508eaef3f4ad04320f73d9498302295635--mpfr-4.2.1.bottle_manifest.json\n",
            "==> Pouring mpfr--4.2.1.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/mpfr/4.2.1: 32 files, 3.9MB\n",
            "==> Installing llama.cpp dependency: libmpc\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libmpc/manifests/1.3.1\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/fdfa98e0f8bb3ce075cb32776ac2345aa2f89252706c162aecfc841085fa76be--libmpc-1.3.1.bottle_manifest.json\n",
            "==> Pouring libmpc--1.3.1.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/libmpc/1.3.1: 14 files, 642.9KB\n",
            "==> Installing llama.cpp dependency: lz4\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/lz4/manifests/1.10.0-1\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/8e11e90eb21a06e0f199af9d80e011e3693c77dd353b2477579d95c8471a5802--lz4-1.10.0-1.bottle_manifest.json\n",
            "==> Pouring lz4--1.10.0.x86_64_linux.bottle.1.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/lz4/1.10.0: 24 files, 798.7KB\n",
            "==> Installing llama.cpp dependency: xz\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/xz/manifests/5.6.3\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/e68799185cc17334108ba286ba8c3df0587c9fd8375647d85f7157b62a797599--xz-5.6.3.bottle_manifest.json\n",
            "==> Pouring xz--5.6.3.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/xz/5.6.3: 97 files, 2MB\n",
            "==> Installing llama.cpp dependency: zlib\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/zlib/manifests/1.3.1\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/f68d0caf232d52f2aa586abefbbfd7e958e384d84f3967008fa83de94b5f10ae--zlib-1.3.1.bottle_manifest.json\n",
            "==> Pouring zlib--1.3.1.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/zlib/1.3.1: 14 files, 476.0KB\n",
            "==> Installing llama.cpp dependency: zstd\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/zstd/manifests/1.5.6\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/29403e0df5404d8aeca0e750ac135ec9ef44fc5eeb6df69170ed602acabf0ffb--zstd-1.5.6.bottle_manifest.json\n",
            "==> Pouring zstd--1.5.6.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/zstd/1.5.6: 32 files, 2.9MB\n",
            "==> Installing llama.cpp dependency: binutils\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/binutils/manifests/2.43.1\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/8111b6fd65822d749b89a471ec543eaf84471287fa7b13113cf3075efee5f0b6--binutils-2.43.1.bottle_manifest.json\n",
            "==> Pouring binutils--2.43.1.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/binutils/2.43.1: 6,513 files, 394.5MB\n",
            "==> Installing llama.cpp dependency: gcc\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/gcc/manifests/14.2.0_1\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/cece94dbe926093c968a24f66b9a0172afe5cc2ef22253029bc591147237045b--gcc-14.2.0_1.bottle_manifest.json\n",
            "==> Pouring gcc--14.2.0_1.x86_64_linux.bottle.tar.gz\n",
            "==> Creating the GCC specs file: /home/linuxbrew/.linuxbrew/Cellar/gcc/14.2.0_1/bin/../lib/gcc/current/gcc/x86_64-pc-linux-gnu/14/specs\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/gcc/14.2.0_1: 2,105 files, 550.9MB\n",
            "==> Installing llama.cpp dependency: openblas\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/openblas/manifests/0.3.28\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/60a317040c885298623bef2b9693411b082cc4a1e706301e19c41d2b1eef9300--openblas-0.3.28.bottle_manifest.json\n",
            "==> Pouring openblas--0.3.28.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/openblas/0.3.28: 24 files, 93.5MB\n",
            "==> Installing llama.cpp dependency: brotli\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/brotli/manifests/1.1.0-1\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/565098509cdfa90593ec9a41b41239f073843f88caed60ddaa3e6194ac4defda--brotli-1.1.0-1.bottle_manifest.json\n",
            "==> Pouring brotli--1.1.0.x86_64_linux.bottle.1.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/brotli/1.1.0: 25 files, 983.7KB\n",
            "==> Installing llama.cpp dependency: libnghttp2\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libnghttp2/manifests/1.64.0\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/ca092fa9d99f26d52103722d42230c00f21eb8a4a36bf1d40fc9d5f798562d92--libnghttp2-1.64.0.bottle_manifest.json\n",
            "==> Pouring libnghttp2--1.64.0.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/libnghttp2/1.64.0: 15 files, 902.9KB\n",
            "==> Installing llama.cpp dependency: ca-certificates\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/ca-certificates/manifests/2024-09-24\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/338dad7c2ff7c822cda7c417944521589856741c0fbd7a7f07b88a18d7fb7e05--ca-certificates-2024-09-24.bottle_manifest.json\n",
            "==> Pouring ca-certificates--2024-09-24.all.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/ca-certificates/2024-09-24: 4 files, 252.9KB\n",
            "==> Installing llama.cpp dependency: openssl@3\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/openssl/3/manifests/3.4.0\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/a8a169d38329b14f967d497d0ea77eee6dc5444175093fc7b26026b357e81736--openssl@3-3.4.0.bottle_manifest.json\n",
            "==> Pouring openssl@3--3.4.0.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/openssl@3/3.4.0: 7,246 files, 40.0MB\n",
            "==> Installing llama.cpp dependency: libssh2\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libssh2/manifests/1.11.1\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/6d2495eb2b5f37f7931b23940ceb29db14a4742a49d1d8cce26964ad91a03f26--libssh2-1.11.1.bottle_manifest.json\n",
            "==> Pouring libssh2--1.11.1.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/libssh2/1.11.1: 202 files, 1.5MB\n",
            "==> Installing llama.cpp dependency: rtmpdump\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/rtmpdump/manifests/2.4-20151223_3\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/b40cb4d6b301aad8ce26f9deb74a74c0d98d1868d19881f9bff55b81d6f11e50--rtmpdump-2.4-20151223_3.bottle_manifest.json\n",
            "==> Pouring rtmpdump--2.4-20151223_3.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/rtmpdump/2.4-20151223_3: 21 files, 630.0KB\n",
            "==> Installing llama.cpp dependency: libunistring\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libunistring/manifests/1.3\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/a570da63bc1839c7e217f203abd54d4d873ebd6b99f6e88994d0e79e2ebe987c--libunistring-1.3.bottle_manifest.json\n",
            "==> Pouring libunistring--1.3.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/libunistring/1.3: 60 files, 6.0MB\n",
            "==> Installing llama.cpp dependency: libidn2\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libidn2/manifests/2.3.7\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/45d1d4d2930c4782bf53e761a1c0166cd8a40f4193ac8c44e86f0b6708e80354--libidn2-2.3.7.bottle_manifest.json\n",
            "==> Pouring libidn2--2.3.7.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/libidn2/2.3.7: 82 files, 1.2MB\n",
            "==> Installing llama.cpp dependency: ncurses\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/ncurses/manifests/6.5\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/b2f8ce4e08b15832435170efd265346225ee388d5baab3d5c50e3a77c5673b5a--ncurses-6.5.bottle_manifest.json\n",
            "==> Pouring ncurses--6.5.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/ncurses/6.5: 4,037 files, 10.9MB\n",
            "==> Installing llama.cpp dependency: libedit\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libedit/manifests/20240808-3.1\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/29a41913ba5a0184006508d5ff85032fddf36d6ff90f0dfd2faea711a1c12ac0--libedit-20240808-3.1.bottle_manifest.json\n",
            "==> Pouring libedit--20240808-3.1.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/libedit/20240808-3.1: 55 files, 795.6KB\n",
            "==> Installing llama.cpp dependency: krb5\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/krb5/manifests/1.21.3\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/c5793441ca90aa09420dddd84f19d4aaf86da4f0b3f60c84940d77b1cb4c6863--krb5-1.21.3.bottle_manifest.json\n",
            "==> Pouring krb5--1.21.3.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/krb5/1.21.3: 164 files, 5.3MB\n",
            "==> Installing llama.cpp dependency: readline\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/readline/manifests/8.2.13\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/aa1afa38997a2866d91c81fdda8b36d436cd4ea7a82aed07d13c83c56eb3460e--readline-8.2.13.bottle_manifest.json\n",
            "==> Pouring readline--8.2.13.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/readline/8.2.13: 51 files, 2MB\n",
            "==> Installing llama.cpp dependency: libxcrypt\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/libxcrypt/manifests/4.4.36\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/950e230307625f9e57d74f0076caab42b6c67a325c70b83efa2c9cc84be1f839--libxcrypt-4.4.36.bottle_manifest.json\n",
            "==> Pouring libxcrypt--4.4.36.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/libxcrypt/4.4.36: 25 files, 371.8KB\n",
            "==> Installing llama.cpp dependency: sqlite\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/sqlite/manifests/3.47.0\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/2acd26e317f3463995d9c8df6d1f6660834a2adccf6448e6166f34a89d607683--sqlite-3.47.0.bottle_manifest.json\n",
            "==> Pouring sqlite--3.47.0.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/sqlite/3.47.0: 13 files, 6.3MB\n",
            "==> Installing llama.cpp dependency: util-linux\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/util-linux/manifests/2.40.2-1\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/635c3a4838ab534b3fed900de735d2527a71bca53917fcc61cc683223c724e8a--util-linux-2.40.2-1.bottle_manifest.json\n",
            "==> Pouring util-linux--2.40.2.x86_64_linux.bottle.1.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/util-linux/2.40.2: 443 files, 25.7MB\n",
            "==> Installing llama.cpp dependency: openldap\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/openldap/manifests/2.6.8\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/521e6d28774a296c05aaf8bccd4a248f5bbfe6ad48d824592473a62c51c48a0d--openldap-2.6.8.bottle_manifest.json\n",
            "==> Pouring openldap--2.6.8.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/openldap/2.6.8: 344 files, 8.8MB\n",
            "==> Installing llama.cpp dependency: curl\n",
            "==> Downloading https://ghcr.io/v2/homebrew/core/curl/manifests/8.11.0_1-1\n",
            "Already downloaded: /root/.cache/Homebrew/downloads/5d24dadbb4e423eafb763d5840ef3ac63f8d8886a37958e637aba6ff20333bd3--curl-8.11.0_1-1.bottle_manifest.json\n",
            "==> Pouring curl--8.11.0_1.x86_64_linux.bottle.1.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/curl/8.11.0_1: 532 files, 5.0MB\n",
            "==> Installing llama.cpp\n",
            "==> Pouring llama.cpp--4071.x86_64_linux.bottle.tar.gz\n",
            "🍺  /home/linuxbrew/.linuxbrew/Cellar/llama.cpp/4071: 116 files, 39.3MB\n",
            "==> Running `brew cleanup llama.cpp`...\n",
            "Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\n",
            "Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download Qwen/Qwen1.5-0.5B-Chat-GGUF qwen1_5-0_5b-chat-q5_k_m.gguf --local-dir . --local-dir-use-symlinks False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyiUXpkzrcwC",
        "outputId": "e2933dd8-0db5-4871-b9c1-99fa57f68e19"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/commands/download.py:139: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.\n",
            "  warnings.warn(\n",
            "Downloading 'qwen1_5-0_5b-chat-q5_k_m.gguf' to '.cache/huggingface/download/qwen1_5-0_5b-chat-q5_k_m.gguf.6cb21dcd237471452d1c4616155e7f857c88d6388afadaccf50599ad3521aa83.incomplete'\n",
            "qwen1_5-0_5b-chat-q5_k_m.gguf: 100% 459M/459M [00:20<00:00, 22.1MB/s]\n",
            "Download complete. Moving file to qwen1_5-0_5b-chat-q5_k_m.gguf\n",
            "qwen1_5-0_5b-chat-q5_k_m.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/home/linuxbrew/.linuxbrew/Cellar/llama.cpp/3497/bin/llama-cli -m ./qwen1_5-0_5b-chat-q5_k_m.gguf -p \"You are a helpful assistant\" -cnv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE5ab8-7syDM",
        "outputId": "b647f91e-f254-4b55-d837-e095bef44e80"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: /home/linuxbrew/.linuxbrew/Cellar/llama.cpp/3497/bin/llama-cli: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# huggingface模型转换及量化"
      ],
      "metadata": {
        "id": "qIkFjtN1s5bL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download --resume-download THUDM/glm-4-9b-chat --local-dir ./glm-4-9b-chat --local-dir-use-symlinks False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSrbSVm2s8V0",
        "outputId": "077d7e7d-12d4-4480-90c8-6c17c5ca4892"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "model-00004-of-00010.safetensors:  42% 818M/1.93G [00:20<00:25, 43.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  42% 818M/1.95G [00:20<00:26, 42.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  44% 807M/1.82G [00:19<00:23, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  41% 807M/1.97G [00:19<00:26, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  46% 828M/1.82G [00:20<00:22, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  43% 828M/1.93G [00:20<00:25, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  46% 839M/1.82G [00:20<00:22, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  42% 828M/1.97G [00:20<00:26, 43.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  43% 828M/1.93G [00:20<00:25, 43.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  43% 828M/1.95G [00:20<00:26, 42.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  45% 818M/1.82G [00:19<00:23, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  42% 818M/1.97G [00:19<00:26, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  46% 839M/1.82G [00:20<00:22, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  44% 839M/1.93G [00:20<00:25, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  47% 849M/1.82G [00:20<00:22, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  43% 839M/1.97G [00:20<00:26, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  44% 839M/1.93G [00:20<00:25, 43.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  43% 839M/1.95G [00:20<00:25, 42.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  46% 828M/1.82G [00:20<00:23, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  42% 828M/1.97G [00:20<00:26, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  47% 849M/1.82G [00:20<00:22, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  44% 849M/1.93G [00:20<00:25, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  47% 860M/1.82G [00:20<00:22, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  43% 849M/1.97G [00:20<00:25, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  44% 849M/1.93G [00:20<00:25, 43.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  44% 849M/1.95G [00:20<00:25, 42.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  46% 839M/1.82G [00:20<00:22, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  43% 839M/1.97G [00:20<00:26, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  47% 860M/1.82G [00:20<00:22, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  45% 860M/1.93G [00:20<00:24, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  48% 870M/1.82G [00:20<00:21, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  44% 860M/1.97G [00:20<00:27, 40.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  47% 849M/1.82G [00:20<00:22, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  44% 860M/1.95G [00:21<00:26, 40.4MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  45% 860M/1.93G [00:21<00:26, 39.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  43% 849M/1.97G [00:20<00:26, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  45% 870M/1.93G [00:21<00:24, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  48% 870M/1.82G [00:21<00:23, 40.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  49% 881M/1.82G [00:21<00:23, 39.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  47% 860M/1.82G [00:20<00:22, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  45% 870M/1.95G [00:21<00:26, 41.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  44% 860M/1.97G [00:20<00:25, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  45% 870M/1.93G [00:21<00:27, 38.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  44% 870M/1.97G [00:21<00:31, 34.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  46% 881M/1.93G [00:21<00:25, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  49% 891M/1.82G [00:21<00:22, 40.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  48% 870M/1.82G [00:20<00:22, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  45% 881M/1.95G [00:21<00:25, 41.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  44% 870M/1.97G [00:21<00:25, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  49% 881M/1.82G [00:21<00:25, 36.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  46% 881M/1.93G [00:21<00:27, 38.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  46% 891M/1.93G [00:21<00:24, 41.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  45% 881M/1.97G [00:21<00:31, 34.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  50% 902M/1.82G [00:21<00:22, 41.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  49% 881M/1.82G [00:21<00:21, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  46% 891M/1.95G [00:21<00:25, 41.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  49% 891M/1.82G [00:21<00:24, 38.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  45% 881M/1.97G [00:21<00:25, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  46% 891M/1.93G [00:21<00:26, 39.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  47% 902M/1.93G [00:21<00:24, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  45% 891M/1.97G [00:21<00:29, 36.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  50% 912M/1.82G [00:21<00:21, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  49% 891M/1.82G [00:21<00:21, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  50% 902M/1.82G [00:22<00:23, 39.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  46% 902M/1.95G [00:22<00:25, 41.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  45% 891M/1.97G [00:21<00:26, 40.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  47% 902M/1.93G [00:22<00:25, 40.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  47% 912M/1.93G [00:22<00:23, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  46% 902M/1.97G [00:22<00:27, 38.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  51% 923M/1.82G [00:22<00:21, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  50% 902M/1.82G [00:21<00:21, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  50% 912M/1.82G [00:22<00:22, 40.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  47% 912M/1.95G [00:22<00:24, 41.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  46% 902M/1.97G [00:21<00:26, 39.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  47% 912M/1.93G [00:22<00:24, 40.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  48% 923M/1.93G [00:22<00:23, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  46% 912M/1.97G [00:22<00:26, 40.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  51% 933M/1.82G [00:22<00:20, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  50% 912M/1.82G [00:21<00:20, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  51% 923M/1.82G [00:22<00:21, 41.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  47% 923M/1.95G [00:22<00:24, 42.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  46% 912M/1.97G [00:22<00:25, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  48% 923M/1.93G [00:22<00:24, 41.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  48% 933M/1.93G [00:22<00:23, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  47% 923M/1.97G [00:22<00:25, 41.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  51% 923M/1.82G [00:22<00:20, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  52% 944M/1.82G [00:22<00:20, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  51% 933M/1.82G [00:22<00:20, 42.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  48% 933M/1.95G [00:22<00:24, 42.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  47% 923M/1.97G [00:22<00:25, 41.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  48% 933M/1.93G [00:22<00:23, 41.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  49% 944M/1.93G [00:22<00:22, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  47% 933M/1.97G [00:22<00:24, 41.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  51% 933M/1.82G [00:22<00:20, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  53% 954M/1.82G [00:22<00:20, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  52% 944M/1.82G [00:22<00:20, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  49% 944M/1.95G [00:23<00:23, 42.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  47% 933M/1.97G [00:22<00:24, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  49% 944M/1.93G [00:23<00:23, 42.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  50% 954M/1.93G [00:23<00:22, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  48% 944M/1.97G [00:23<00:24, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  52% 944M/1.82G [00:22<00:20, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  53% 965M/1.82G [00:23<00:19, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  53% 954M/1.82G [00:23<00:20, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  49% 954M/1.95G [00:23<00:23, 42.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  48% 944M/1.97G [00:22<00:24, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  50% 954M/1.93G [00:23<00:22, 42.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  50% 965M/1.93G [00:23<00:22, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  48% 954M/1.97G [00:23<00:23, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  53% 954M/1.82G [00:22<00:19, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  54% 975M/1.82G [00:23<00:19, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  53% 965M/1.82G [00:23<00:19, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  50% 965M/1.95G [00:23<00:23, 42.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  48% 954M/1.97G [00:23<00:23, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  50% 965M/1.93G [00:23<00:22, 42.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  51% 975M/1.93G [00:23<00:22, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  49% 965M/1.97G [00:23<00:23, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  53% 965M/1.82G [00:23<00:19, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  54% 986M/1.82G [00:23<00:19, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  54% 975M/1.82G [00:23<00:19, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  50% 975M/1.95G [00:23<00:22, 42.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  49% 965M/1.97G [00:23<00:23, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  51% 975M/1.93G [00:23<00:22, 42.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  51% 986M/1.93G [00:23<00:21, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  50% 975M/1.97G [00:23<00:23, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  54% 975M/1.82G [00:23<00:19, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  55% 996M/1.82G [00:23<00:19, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  54% 986M/1.82G [00:23<00:19, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  51% 986M/1.95G [00:24<00:22, 42.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  50% 975M/1.97G [00:23<00:23, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  51% 986M/1.93G [00:24<00:22, 42.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  52% 996M/1.93G [00:24<00:21, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  50% 986M/1.97G [00:24<00:22, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  54% 986M/1.82G [00:23<00:19, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  55% 1.01G/1.82G [00:24<00:18, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  55% 996M/1.82G [00:24<00:18, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  51% 996M/1.95G [00:24<00:22, 42.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  50% 986M/1.97G [00:23<00:22, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  52% 996M/1.93G [00:24<00:21, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  52% 1.01G/1.93G [00:24<00:21, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  51% 996M/1.97G [00:24<00:22, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  55% 996M/1.82G [00:23<00:18, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  56% 1.02G/1.82G [00:24<00:18, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  55% 1.01G/1.82G [00:24<00:18, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  52% 1.01G/1.95G [00:24<00:21, 42.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  51% 996M/1.97G [00:24<00:22, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  52% 1.01G/1.93G [00:24<00:21, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  53% 1.02G/1.93G [00:24<00:21, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  51% 1.01G/1.97G [00:24<00:22, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  57% 1.03G/1.82G [00:24<00:18, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  55% 1.01G/1.82G [00:24<00:18, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  56% 1.02G/1.82G [00:24<00:18, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  52% 1.02G/1.95G [00:24<00:21, 42.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  51% 1.01G/1.97G [00:24<00:22, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  53% 1.02G/1.93G [00:24<00:21, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  52% 1.02G/1.97G [00:24<00:22, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  53% 1.03G/1.93G [00:24<00:21, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  57% 1.04G/1.82G [00:24<00:17, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  56% 1.02G/1.82G [00:24<00:18, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  57% 1.03G/1.82G [00:24<00:18, 43.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  53% 1.03G/1.95G [00:24<00:21, 42.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  52% 1.02G/1.97G [00:24<00:21, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  53% 1.03G/1.93G [00:25<00:20, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  52% 1.03G/1.97G [00:25<00:21, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  54% 1.04G/1.93G [00:25<00:20, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  58% 1.05G/1.82G [00:25<00:17, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  57% 1.03G/1.82G [00:24<00:18, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  57% 1.04G/1.82G [00:25<00:17, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  53% 1.04G/1.95G [00:25<00:21, 42.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  52% 1.03G/1.97G [00:24<00:21, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  54% 1.04G/1.93G [00:25<00:20, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  53% 1.04G/1.97G [00:25<00:21, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  54% 1.05G/1.93G [00:25<00:20, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  58% 1.06G/1.82G [00:25<00:17, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  57% 1.04G/1.82G [00:24<00:18, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  58% 1.05G/1.82G [00:25<00:17, 43.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  54% 1.05G/1.95G [00:25<00:21, 42.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  53% 1.04G/1.97G [00:24<00:21, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  54% 1.05G/1.93G [00:25<00:20, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  53% 1.05G/1.97G [00:25<00:21, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  55% 1.06G/1.93G [00:25<00:20, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  59% 1.07G/1.82G [00:25<00:17, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  58% 1.05G/1.82G [00:25<00:17, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  58% 1.06G/1.82G [00:25<00:17, 43.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  54% 1.06G/1.95G [00:25<00:20, 42.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  53% 1.05G/1.97G [00:25<00:21, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  55% 1.06G/1.93G [00:25<00:20, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  54% 1.06G/1.97G [00:25<00:20, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  55% 1.07G/1.93G [00:25<00:20, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  59% 1.08G/1.82G [00:25<00:16, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  58% 1.06G/1.82G [00:25<00:17, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  59% 1.07G/1.82G [00:25<00:17, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  55% 1.07G/1.95G [00:25<00:20, 42.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  54% 1.06G/1.97G [00:25<00:21, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  55% 1.07G/1.93G [00:26<00:19, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  54% 1.07G/1.97G [00:26<00:20, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  56% 1.08G/1.93G [00:26<00:19, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  60% 1.09G/1.82G [00:26<00:16, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  59% 1.07G/1.82G [00:25<00:17, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  59% 1.08G/1.82G [00:26<00:16, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  56% 1.08G/1.95G [00:26<00:20, 42.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  54% 1.07G/1.97G [00:25<00:20, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  56% 1.08G/1.93G [00:26<00:19, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  55% 1.08G/1.97G [00:26<00:20, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  57% 1.09G/1.93G [00:26<00:19, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  61% 1.10G/1.82G [00:26<00:16, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  59% 1.08G/1.82G [00:25<00:17, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  60% 1.09G/1.82G [00:26<00:16, 43.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  56% 1.09G/1.95G [00:26<00:19, 42.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  55% 1.08G/1.97G [00:25<00:20, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  57% 1.09G/1.93G [00:26<00:19, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  55% 1.09G/1.97G [00:26<00:20, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  57% 1.10G/1.93G [00:26<00:19, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  61% 1.11G/1.82G [00:26<00:16, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  60% 1.09G/1.82G [00:26<00:16, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  61% 1.10G/1.82G [00:26<00:16, 43.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  57% 1.10G/1.95G [00:26<00:19, 42.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  55% 1.09G/1.97G [00:26<00:20, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  57% 1.10G/1.93G [00:26<00:19, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  56% 1.10G/1.97G [00:26<00:19, 43.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  58% 1.11G/1.93G [00:26<00:19, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  62% 1.12G/1.82G [00:26<00:16, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  61% 1.10G/1.82G [00:26<00:16, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  61% 1.11G/1.82G [00:26<00:16, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  57% 1.11G/1.95G [00:26<00:19, 42.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  56% 1.10G/1.97G [00:26<00:20, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  58% 1.11G/1.93G [00:26<00:18, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  56% 1.11G/1.97G [00:26<00:19, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  58% 1.12G/1.93G [00:26<00:18, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  62% 1.13G/1.82G [00:27<00:15, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  61% 1.11G/1.82G [00:26<00:16, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  62% 1.12G/1.82G [00:27<00:15, 43.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  58% 1.12G/1.95G [00:27<00:19, 42.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  56% 1.11G/1.97G [00:26<00:19, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  58% 1.12G/1.93G [00:27<00:18, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  57% 1.12G/1.97G [00:27<00:19, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  59% 1.13G/1.93G [00:27<00:18, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  63% 1.14G/1.82G [00:27<00:15, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  62% 1.12G/1.82G [00:26<00:16, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  62% 1.13G/1.82G [00:27<00:15, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  58% 1.13G/1.95G [00:27<00:18, 42.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  57% 1.12G/1.97G [00:26<00:19, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  59% 1.13G/1.93G [00:27<00:18, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  58% 1.13G/1.97G [00:27<00:19, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  59% 1.14G/1.93G [00:27<00:18, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  64% 1.15G/1.82G [00:27<00:15, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  62% 1.13G/1.82G [00:27<00:15, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  63% 1.14G/1.82G [00:27<00:15, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  59% 1.14G/1.95G [00:27<00:18, 42.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  58% 1.13G/1.97G [00:27<00:19, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  59% 1.14G/1.93G [00:27<00:18, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  58% 1.14G/1.97G [00:27<00:19, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  60% 1.15G/1.93G [00:27<00:18, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  64% 1.16G/1.82G [00:27<00:15, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  63% 1.14G/1.82G [00:27<00:15, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  64% 1.15G/1.82G [00:27<00:15, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  58% 1.14G/1.97G [00:27<00:19, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  59% 1.15G/1.95G [00:27<00:18, 42.7MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  60% 1.15G/1.93G [00:27<00:17, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  59% 1.15G/1.97G [00:27<00:18, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  60% 1.16G/1.93G [00:27<00:17, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  65% 1.17G/1.82G [00:27<00:14, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  64% 1.15G/1.82G [00:27<00:15, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  64% 1.16G/1.82G [00:28<00:14, 43.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  59% 1.15G/1.97G [00:27<00:18, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  60% 1.16G/1.95G [00:28<00:18, 42.8MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  60% 1.16G/1.93G [00:28<00:17, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  59% 1.16G/1.97G [00:28<00:18, 43.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  61% 1.17G/1.93G [00:28<00:17, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  65% 1.18G/1.82G [00:28<00:14, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  64% 1.16G/1.82G [00:27<00:15, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  65% 1.17G/1.82G [00:28<00:14, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  59% 1.16G/1.97G [00:27<00:18, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  60% 1.17G/1.95G [00:28<00:18, 42.7MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  61% 1.17G/1.93G [00:28<00:17, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  60% 1.17G/1.97G [00:28<00:18, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  61% 1.18G/1.93G [00:28<00:17, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  66% 1.20G/1.82G [00:28<00:14, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  65% 1.17G/1.82G [00:28<00:14, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  65% 1.18G/1.82G [00:28<00:14, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  60% 1.17G/1.97G [00:28<00:18, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  61% 1.18G/1.95G [00:28<00:17, 42.7MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  61% 1.18G/1.93G [00:28<00:17, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  60% 1.18G/1.97G [00:28<00:18, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  62% 1.20G/1.93G [00:28<00:17, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  66% 1.21G/1.82G [00:28<00:14, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  65% 1.18G/1.82G [00:28<00:14, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  66% 1.20G/1.82G [00:28<00:14, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  60% 1.18G/1.97G [00:28<00:18, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  61% 1.20G/1.95G [00:28<00:17, 42.8MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  62% 1.20G/1.93G [00:28<00:16, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  61% 1.20G/1.97G [00:28<00:17, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  63% 1.21G/1.93G [00:28<00:16, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  67% 1.22G/1.82G [00:28<00:13, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  66% 1.21G/1.82G [00:29<00:14, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  66% 1.20G/1.82G [00:28<00:14, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  61% 1.20G/1.97G [00:28<00:17, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  62% 1.21G/1.95G [00:29<00:17, 42.8MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  63% 1.21G/1.93G [00:29<00:16, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  61% 1.21G/1.97G [00:29<00:17, 43.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  63% 1.22G/1.93G [00:29<00:16, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  68% 1.23G/1.82G [00:29<00:13, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  67% 1.22G/1.82G [00:29<00:13, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  66% 1.21G/1.82G [00:28<00:14, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  61% 1.21G/1.97G [00:28<00:17, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  63% 1.22G/1.95G [00:29<00:17, 42.7MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  63% 1.22G/1.93G [00:29<00:16, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  62% 1.22G/1.97G [00:29<00:17, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  64% 1.23G/1.93G [00:29<00:16, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  68% 1.24G/1.82G [00:29<00:13, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  68% 1.23G/1.82G [00:29<00:13, 43.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  67% 1.22G/1.82G [00:29<00:13, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  62% 1.22G/1.97G [00:29<00:17, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  63% 1.23G/1.95G [00:29<00:16, 42.7MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  64% 1.23G/1.93G [00:29<00:16, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  62% 1.23G/1.97G [00:29<00:17, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  69% 1.25G/1.82G [00:29<00:13, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  64% 1.24G/1.93G [00:29<00:16, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  68% 1.24G/1.82G [00:29<00:13, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  68% 1.23G/1.82G [00:29<00:13, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  62% 1.23G/1.97G [00:29<00:17, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  64% 1.24G/1.95G [00:29<00:16, 42.8MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  64% 1.24G/1.93G [00:29<00:15, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  63% 1.24G/1.97G [00:29<00:16, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  69% 1.26G/1.82G [00:29<00:12, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  65% 1.25G/1.93G [00:29<00:15, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  69% 1.25G/1.82G [00:29<00:13, 43.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  68% 1.24G/1.82G [00:29<00:13, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  63% 1.24G/1.97G [00:29<00:16, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  64% 1.25G/1.95G [00:30<00:16, 42.9MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  65% 1.25G/1.93G [00:30<00:15, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  63% 1.25G/1.97G [00:30<00:16, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  70% 1.27G/1.82G [00:30<00:12, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  65% 1.26G/1.93G [00:30<00:15, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  69% 1.26G/1.82G [00:30<00:12, 43.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  69% 1.25G/1.82G [00:29<00:13, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  63% 1.25G/1.97G [00:29<00:16, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  65% 1.26G/1.95G [00:30<00:16, 42.8MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  65% 1.26G/1.93G [00:30<00:15, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  64% 1.26G/1.97G [00:30<00:16, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  70% 1.28G/1.82G [00:30<00:12, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  66% 1.27G/1.93G [00:30<00:15, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  70% 1.27G/1.82G [00:30<00:12, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  69% 1.26G/1.82G [00:29<00:12, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  64% 1.26G/1.97G [00:30<00:16, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  65% 1.27G/1.95G [00:30<00:15, 42.8MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  66% 1.27G/1.93G [00:30<00:15, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  64% 1.27G/1.97G [00:30<00:16, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  71% 1.29G/1.82G [00:30<00:12, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  66% 1.28G/1.93G [00:30<00:15, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  70% 1.28G/1.82G [00:30<00:12, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  70% 1.27G/1.82G [00:30<00:12, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  64% 1.27G/1.97G [00:30<00:16, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  66% 1.28G/1.95G [00:30<00:15, 42.7MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  66% 1.28G/1.93G [00:30<00:14, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  65% 1.28G/1.97G [00:30<00:15, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  72% 1.30G/1.82G [00:30<00:11, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  67% 1.29G/1.93G [00:30<00:14, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  71% 1.29G/1.82G [00:30<00:12, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  70% 1.28G/1.82G [00:30<00:12, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  65% 1.28G/1.97G [00:30<00:15, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  66% 1.29G/1.95G [00:31<00:15, 42.8MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  67% 1.29G/1.93G [00:31<00:14, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  66% 1.29G/1.97G [00:31<00:15, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  72% 1.31G/1.82G [00:31<00:11, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  67% 1.30G/1.93G [00:31<00:14, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  72% 1.30G/1.82G [00:31<00:11, 43.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  71% 1.29G/1.82G [00:30<00:12, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  66% 1.29G/1.97G [00:30<00:15, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  67% 1.30G/1.95G [00:31<00:15, 42.9MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  67% 1.30G/1.93G [00:31<00:14, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  66% 1.30G/1.97G [00:31<00:15, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  73% 1.32G/1.82G [00:31<00:11, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  68% 1.31G/1.93G [00:31<00:14, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  72% 1.31G/1.82G [00:31<00:11, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  72% 1.30G/1.82G [00:30<00:11, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  66% 1.30G/1.97G [00:31<00:15, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  68% 1.31G/1.93G [00:31<00:14, 43.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  67% 1.31G/1.95G [00:31<00:14, 42.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  67% 1.31G/1.97G [00:31<00:15, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  73% 1.33G/1.82G [00:31<00:11, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  73% 1.32G/1.82G [00:31<00:11, 43.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  69% 1.32G/1.93G [00:31<00:14, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  72% 1.31G/1.82G [00:31<00:11, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  67% 1.31G/1.97G [00:31<00:15, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  69% 1.32G/1.93G [00:31<00:14, 43.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  68% 1.32G/1.95G [00:31<00:15, 41.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  67% 1.32G/1.97G [00:31<00:15, 41.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  74% 1.34G/1.82G [00:31<00:10, 43.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  73% 1.32G/1.82G [00:31<00:11, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  69% 1.33G/1.93G [00:31<00:15, 38.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  73% 1.33G/1.82G [00:32<00:12, 38.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  67% 1.32G/1.97G [00:31<00:14, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  68% 1.33G/1.95G [00:32<00:14, 41.4MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  69% 1.33G/1.93G [00:32<00:14, 40.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  75% 1.35G/1.82G [00:32<00:10, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  73% 1.33G/1.82G [00:31<00:11, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  68% 1.33G/1.97G [00:32<00:16, 38.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  74% 1.34G/1.82G [00:32<00:11, 39.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  68% 1.33G/1.97G [00:31<00:14, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  70% 1.34G/1.93G [00:32<00:15, 36.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  70% 1.34G/1.93G [00:32<00:14, 41.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  69% 1.34G/1.95G [00:32<00:14, 41.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  75% 1.36G/1.82G [00:32<00:10, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  74% 1.34G/1.82G [00:31<00:10, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  68% 1.34G/1.97G [00:32<00:15, 39.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  75% 1.35G/1.82G [00:32<00:11, 40.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  68% 1.34G/1.97G [00:32<00:14, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  70% 1.35G/1.93G [00:32<00:14, 38.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  70% 1.35G/1.93G [00:32<00:13, 42.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  70% 1.35G/1.95G [00:32<00:14, 42.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  76% 1.37G/1.82G [00:32<00:10, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  75% 1.35G/1.82G [00:32<00:10, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  69% 1.35G/1.97G [00:32<00:15, 38.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  75% 1.36G/1.82G [00:32<00:11, 39.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  71% 1.36G/1.93G [00:32<00:14, 39.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  71% 1.36G/1.93G [00:32<00:13, 42.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  70% 1.36G/1.95G [00:32<00:13, 42.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  76% 1.38G/1.82G [00:32<00:09, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  69% 1.35G/1.97G [00:32<00:16, 36.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  75% 1.36G/1.82G [00:32<00:10, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  69% 1.36G/1.97G [00:32<00:15, 39.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  76% 1.37G/1.82G [00:33<00:10, 40.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  71% 1.37G/1.93G [00:33<00:13, 40.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  71% 1.37G/1.93G [00:33<00:13, 42.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  71% 1.37G/1.95G [00:33<00:13, 42.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  77% 1.39G/1.82G [00:33<00:09, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  69% 1.36G/1.97G [00:32<00:15, 37.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  76% 1.37G/1.82G [00:32<00:10, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  70% 1.37G/1.97G [00:33<00:14, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  76% 1.38G/1.82G [00:33<00:10, 41.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  72% 1.38G/1.93G [00:33<00:13, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  72% 1.38G/1.93G [00:33<00:12, 42.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  71% 1.38G/1.95G [00:33<00:13, 42.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  77% 1.41G/1.82G [00:33<00:09, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  70% 1.37G/1.97G [00:32<00:15, 38.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  76% 1.38G/1.82G [00:32<00:10, 41.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  70% 1.38G/1.97G [00:33<00:14, 41.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  77% 1.39G/1.82G [00:33<00:10, 41.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  72% 1.39G/1.93G [00:33<00:12, 41.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  72% 1.39G/1.95G [00:33<00:12, 42.9MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  72% 1.39G/1.93G [00:33<00:12, 42.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  78% 1.42G/1.82G [00:33<00:09, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  70% 1.38G/1.97G [00:33<00:14, 39.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  77% 1.39G/1.82G [00:33<00:10, 41.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  71% 1.39G/1.97G [00:33<00:13, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  77% 1.41G/1.82G [00:33<00:09, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  73% 1.41G/1.93G [00:33<00:12, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  72% 1.41G/1.95G [00:33<00:12, 42.8MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  73% 1.41G/1.93G [00:33<00:12, 42.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  79% 1.43G/1.82G [00:33<00:09, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  71% 1.39G/1.97G [00:33<00:14, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  71% 1.41G/1.97G [00:33<00:13, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  78% 1.42G/1.82G [00:33<00:09, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  73% 1.42G/1.93G [00:34<00:12, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  77% 1.41G/1.82G [00:33<00:11, 36.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  73% 1.42G/1.95G [00:34<00:12, 43.0MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  73% 1.42G/1.93G [00:34<00:11, 42.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  79% 1.44G/1.82G [00:34<00:08, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  71% 1.41G/1.97G [00:33<00:13, 41.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  78% 1.42G/1.82G [00:33<00:08, 44.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  72% 1.42G/1.97G [00:34<00:12, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  79% 1.43G/1.82G [00:34<00:09, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  74% 1.43G/1.93G [00:34<00:11, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  73% 1.43G/1.95G [00:34<00:12, 43.1MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  74% 1.43G/1.93G [00:34<00:11, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  80% 1.45G/1.82G [00:34<00:08, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  72% 1.42G/1.97G [00:33<00:13, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  79% 1.43G/1.82G [00:33<00:08, 44.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  72% 1.43G/1.97G [00:34<00:12, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  79% 1.44G/1.82G [00:34<00:08, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  75% 1.44G/1.93G [00:34<00:11, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  74% 1.44G/1.95G [00:34<00:11, 43.2MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  75% 1.44G/1.93G [00:34<00:11, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  80% 1.46G/1.82G [00:34<00:08, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  72% 1.43G/1.97G [00:34<00:12, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  79% 1.44G/1.82G [00:34<00:08, 43.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  73% 1.44G/1.97G [00:34<00:12, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  80% 1.45G/1.82G [00:34<00:08, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  75% 1.45G/1.93G [00:34<00:11, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  74% 1.45G/1.95G [00:34<00:11, 43.1MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  75% 1.45G/1.93G [00:34<00:11, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  81% 1.47G/1.82G [00:34<00:08, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  73% 1.44G/1.97G [00:34<00:12, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  80% 1.45G/1.82G [00:34<00:08, 43.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  74% 1.45G/1.97G [00:34<00:12, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  80% 1.46G/1.82G [00:34<00:08, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  76% 1.46G/1.93G [00:34<00:11, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  75% 1.46G/1.95G [00:35<00:11, 43.2MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  76% 1.46G/1.93G [00:35<00:10, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  81% 1.48G/1.82G [00:35<00:07, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  74% 1.45G/1.97G [00:34<00:12, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  80% 1.46G/1.82G [00:34<00:08, 43.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  74% 1.46G/1.97G [00:35<00:11, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  81% 1.47G/1.82G [00:35<00:08, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  76% 1.47G/1.93G [00:35<00:10, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  75% 1.47G/1.95G [00:35<00:11, 43.3MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  76% 1.47G/1.93G [00:35<00:10, 43.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  76% 1.48G/1.95G [00:35<00:10, 43.4MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  77% 1.48G/1.93G [00:35<00:10, 43.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  77% 1.49G/1.95G [00:35<00:10, 43.3MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  77% 1.49G/1.93G [00:35<00:10, 43.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  77% 1.50G/1.95G [00:36<00:10, 43.4MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  78% 1.50G/1.93G [00:36<00:09, 42.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  78% 1.51G/1.95G [00:36<00:10, 43.2MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  78% 1.51G/1.93G [00:36<00:09, 43.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  78% 1.52G/1.95G [00:36<00:09, 43.2MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  79% 1.52G/1.93G [00:36<00:09, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  77% 1.48G/1.93G [00:36<00:25, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  81% 1.48G/1.82G [00:36<00:19, 17.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  75% 1.47G/1.97G [00:36<00:29, 16.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  81% 1.47G/1.82G [00:36<00:20, 16.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  74% 1.46G/1.97G [00:36<00:31, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  79% 1.53G/1.95G [00:36<00:09, 43.1MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  79% 1.53G/1.93G [00:36<00:09, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  77% 1.49G/1.93G [00:36<00:19, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  81% 1.48G/1.82G [00:36<00:15, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  82% 1.49G/1.82G [00:36<00:14, 22.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  75% 1.48G/1.97G [00:36<00:22, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  82% 1.49G/1.82G [00:36<00:21, 15.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  75% 1.47G/1.97G [00:36<00:24, 20.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  79% 1.54G/1.95G [00:37<00:09, 43.2MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  80% 1.54G/1.93G [00:37<00:08, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  78% 1.50G/1.93G [00:37<00:15, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  83% 1.50G/1.82G [00:37<00:12, 26.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  82% 1.49G/1.82G [00:36<00:12, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  76% 1.49G/1.97G [00:37<00:18, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  83% 1.51G/1.82G [00:37<00:12, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  75% 1.48G/1.97G [00:36<00:19, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  80% 1.55G/1.95G [00:37<00:09, 43.0MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  81% 1.55G/1.93G [00:37<00:08, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  78% 1.51G/1.93G [00:37<00:13, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  83% 1.50G/1.82G [00:36<00:10, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  83% 1.51G/1.82G [00:37<00:10, 29.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  76% 1.50G/1.97G [00:37<00:16, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  84% 1.52G/1.82G [00:37<00:10, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  76% 1.49G/1.97G [00:36<00:16, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  80% 1.56G/1.95G [00:37<00:08, 42.9MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  81% 1.56G/1.93G [00:37<00:08, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  79% 1.52G/1.93G [00:37<00:12, 33.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  84% 1.52G/1.82G [00:37<00:09, 32.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  83% 1.51G/1.82G [00:37<00:09, 32.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  77% 1.51G/1.97G [00:37<00:14, 32.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  84% 1.53G/1.82G [00:37<00:09, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  76% 1.50G/1.97G [00:37<00:14, 31.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  81% 1.57G/1.95G [00:37<00:08, 43.0MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  82% 1.57G/1.93G [00:37<00:08, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  79% 1.53G/1.93G [00:37<00:11, 35.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  84% 1.53G/1.82G [00:37<00:08, 35.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  84% 1.52G/1.82G [00:37<00:08, 34.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  77% 1.52G/1.97G [00:37<00:12, 34.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  85% 1.54G/1.82G [00:37<00:08, 32.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  77% 1.51G/1.97G [00:37<00:13, 34.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  81% 1.58G/1.95G [00:37<00:08, 43.0MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  82% 1.58G/1.93G [00:37<00:07, 43.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  80% 1.54G/1.93G [00:37<00:10, 37.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  85% 1.54G/1.82G [00:38<00:07, 37.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  84% 1.53G/1.82G [00:37<00:07, 37.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  78% 1.53G/1.97G [00:38<00:11, 36.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  85% 1.55G/1.82G [00:38<00:07, 35.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  77% 1.52G/1.97G [00:37<00:12, 36.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  82% 1.59G/1.95G [00:38<00:08, 43.2MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  83% 1.59G/1.93G [00:38<00:07, 43.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  81% 1.55G/1.93G [00:38<00:09, 39.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  85% 1.55G/1.82G [00:38<00:06, 38.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  85% 1.54G/1.82G [00:37<00:07, 38.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  78% 1.54G/1.97G [00:38<00:11, 38.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  86% 1.56G/1.82G [00:38<00:06, 37.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  78% 1.53G/1.97G [00:37<00:11, 38.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  82% 1.60G/1.95G [00:38<00:07, 43.1MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  83% 1.60G/1.93G [00:38<00:07, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  81% 1.56G/1.93G [00:38<00:09, 40.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  86% 1.56G/1.82G [00:38<00:06, 40.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  85% 1.55G/1.82G [00:38<00:06, 39.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  79% 1.55G/1.97G [00:38<00:10, 39.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  78% 1.54G/1.97G [00:38<00:10, 39.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  87% 1.57G/1.82G [00:38<00:06, 37.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  83% 1.61G/1.95G [00:38<00:07, 43.2MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  84% 1.61G/1.93G [00:38<00:07, 43.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  87% 1.57G/1.82G [00:38<00:05, 41.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  82% 1.57G/1.93G [00:38<00:08, 40.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  86% 1.56G/1.82G [00:38<00:06, 40.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  79% 1.56G/1.97G [00:38<00:09, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  79% 1.55G/1.97G [00:38<00:10, 40.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  87% 1.58G/1.82G [00:38<00:05, 39.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  84% 1.63G/1.95G [00:38<00:07, 43.2MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  84% 1.63G/1.93G [00:38<00:06, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  87% 1.58G/1.82G [00:38<00:05, 41.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  82% 1.58G/1.93G [00:38<00:08, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  87% 1.57G/1.82G [00:38<00:05, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  80% 1.57G/1.97G [00:39<00:09, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  79% 1.56G/1.97G [00:38<00:09, 41.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  88% 1.59G/1.82G [00:39<00:05, 40.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  84% 1.64G/1.95G [00:39<00:07, 43.2MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  85% 1.64G/1.93G [00:39<00:06, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  88% 1.59G/1.82G [00:39<00:05, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  83% 1.59G/1.93G [00:39<00:08, 41.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  87% 1.58G/1.82G [00:38<00:05, 41.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  80% 1.58G/1.97G [00:39<00:09, 41.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  80% 1.57G/1.97G [00:38<00:09, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  88% 1.60G/1.82G [00:39<00:05, 40.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  85% 1.65G/1.95G [00:39<00:06, 43.2MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  85% 1.65G/1.93G [00:39<00:06, 43.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  88% 1.60G/1.82G [00:39<00:04, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  88% 1.59G/1.82G [00:39<00:05, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  83% 1.60G/1.93G [00:39<00:07, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  81% 1.59G/1.97G [00:39<00:08, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  80% 1.58G/1.97G [00:39<00:09, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  89% 1.61G/1.82G [00:39<00:04, 41.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  85% 1.66G/1.95G [00:39<00:06, 43.2MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  86% 1.66G/1.93G [00:39<00:06, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  89% 1.61G/1.82G [00:39<00:04, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  88% 1.60G/1.82G [00:39<00:04, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  84% 1.61G/1.93G [00:39<00:07, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  82% 1.60G/1.97G [00:39<00:08, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  90% 1.63G/1.82G [00:39<00:04, 41.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  81% 1.59G/1.97G [00:39<00:09, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  87% 1.67G/1.93G [00:39<00:06, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  90% 1.63G/1.82G [00:39<00:04, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  89% 1.61G/1.82G [00:39<00:04, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  84% 1.63G/1.93G [00:39<00:07, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  82% 1.61G/1.97G [00:39<00:08, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  86% 1.67G/1.95G [00:40<00:07, 36.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  90% 1.64G/1.82G [00:40<00:04, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  82% 1.60G/1.97G [00:39<00:08, 41.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  87% 1.68G/1.93G [00:40<00:05, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  90% 1.64G/1.82G [00:40<00:04, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  86% 1.68G/1.95G [00:40<00:06, 41.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  90% 1.63G/1.82G [00:39<00:04, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  85% 1.64G/1.93G [00:40<00:06, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  83% 1.63G/1.97G [00:40<00:08, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  91% 1.65G/1.82G [00:40<00:03, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  82% 1.61G/1.97G [00:39<00:08, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  88% 1.69G/1.93G [00:40<00:05, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  91% 1.65G/1.82G [00:40<00:03, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  87% 1.69G/1.95G [00:40<00:06, 41.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  85% 1.65G/1.93G [00:40<00:06, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  90% 1.64G/1.82G [00:39<00:04, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  83% 1.64G/1.97G [00:40<00:07, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  91% 1.66G/1.82G [00:40<00:03, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  83% 1.63G/1.97G [00:40<00:08, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  88% 1.70G/1.93G [00:40<00:05, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  91% 1.66G/1.82G [00:40<00:03, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  87% 1.70G/1.95G [00:40<00:05, 42.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  86% 1.66G/1.93G [00:40<00:06, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  91% 1.65G/1.82G [00:40<00:03, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  84% 1.65G/1.97G [00:40<00:07, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  92% 1.67G/1.82G [00:40<00:03, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  83% 1.64G/1.97G [00:40<00:07, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  89% 1.71G/1.93G [00:40<00:05, 42.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  92% 1.67G/1.82G [00:40<00:03, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  88% 1.71G/1.95G [00:40<00:05, 42.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  87% 1.67G/1.93G [00:40<00:06, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  91% 1.66G/1.82G [00:40<00:03, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  84% 1.66G/1.97G [00:40<00:07, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  92% 1.68G/1.82G [00:41<00:03, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  84% 1.65G/1.97G [00:40<00:07, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  89% 1.72G/1.93G [00:41<00:04, 42.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  92% 1.68G/1.82G [00:41<00:03, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  88% 1.72G/1.95G [00:41<00:05, 42.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  87% 1.68G/1.93G [00:41<00:05, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  92% 1.67G/1.82G [00:40<00:03, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  85% 1.67G/1.97G [00:41<00:06, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  84% 1.66G/1.97G [00:40<00:07, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  93% 1.69G/1.82G [00:41<00:03, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  90% 1.73G/1.93G [00:41<00:04, 42.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  93% 1.69G/1.82G [00:41<00:02, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  89% 1.73G/1.95G [00:41<00:05, 42.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  88% 1.69G/1.93G [00:41<00:05, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  92% 1.68G/1.82G [00:40<00:03, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  85% 1.67G/1.97G [00:41<00:06, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  94% 1.70G/1.82G [00:41<00:02, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  85% 1.68G/1.97G [00:41<00:07, 37.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  90% 1.74G/1.93G [00:41<00:04, 42.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  94% 1.70G/1.82G [00:41<00:02, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  89% 1.74G/1.95G [00:41<00:04, 42.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  88% 1.70G/1.93G [00:41<00:05, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  93% 1.69G/1.82G [00:41<00:02, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  86% 1.69G/1.97G [00:41<00:06, 43.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  85% 1.68G/1.97G [00:41<00:06, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  94% 1.71G/1.82G [00:41<00:02, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  91% 1.75G/1.93G [00:41<00:04, 42.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  94% 1.71G/1.82G [00:41<00:02, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  90% 1.75G/1.95G [00:41<00:04, 42.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  89% 1.71G/1.93G [00:41<00:05, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  94% 1.70G/1.82G [00:41<00:02, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  86% 1.70G/1.97G [00:41<00:06, 43.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  95% 1.72G/1.82G [00:41<00:02, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  86% 1.69G/1.97G [00:41<00:06, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  91% 1.76G/1.93G [00:42<00:03, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  95% 1.72G/1.82G [00:42<00:02, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  89% 1.72G/1.93G [00:42<00:04, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  94% 1.71G/1.82G [00:41<00:02, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  91% 1.76G/1.95G [00:42<00:04, 41.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  87% 1.71G/1.97G [00:42<00:05, 43.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  95% 1.73G/1.82G [00:42<00:01, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  86% 1.70G/1.97G [00:41<00:06, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  92% 1.77G/1.93G [00:42<00:03, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  95% 1.73G/1.82G [00:42<00:01, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  95% 1.72G/1.82G [00:41<00:02, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  90% 1.73G/1.93G [00:42<00:04, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  91% 1.77G/1.95G [00:42<00:04, 42.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  87% 1.72G/1.97G [00:42<00:05, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  96% 1.74G/1.82G [00:42<00:01, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  87% 1.71G/1.97G [00:41<00:06, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  92% 1.78G/1.93G [00:42<00:03, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  96% 1.74G/1.82G [00:42<00:01, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  95% 1.73G/1.82G [00:42<00:01, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  88% 1.73G/1.97G [00:42<00:05, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  90% 1.74G/1.93G [00:42<00:04, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  92% 1.78G/1.95G [00:42<00:04, 40.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  87% 1.72G/1.97G [00:42<00:05, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  96% 1.75G/1.82G [00:42<00:01, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  93% 1.79G/1.93G [00:42<00:03, 43.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  96% 1.74G/1.82G [00:42<00:01, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  96% 1.75G/1.82G [00:42<00:01, 39.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  88% 1.74G/1.97G [00:42<00:05, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  91% 1.75G/1.93G [00:42<00:04, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  88% 1.73G/1.97G [00:42<00:05, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  97% 1.76G/1.82G [00:43<00:01, 41.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  92% 1.79G/1.95G [00:43<00:03, 38.3MB/s]\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  94% 1.80G/1.93G [00:43<00:03, 39.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  96% 1.75G/1.82G [00:42<00:01, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  89% 1.75G/1.97G [00:43<00:05, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  88% 1.74G/1.97G [00:42<00:05, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  91% 1.76G/1.93G [00:43<00:04, 39.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  98% 1.77G/1.82G [00:43<00:01, 41.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  93% 1.80G/1.95G [00:43<00:03, 39.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  97% 1.76G/1.82G [00:43<00:01, 35.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  94% 1.81G/1.93G [00:43<00:02, 40.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  97% 1.76G/1.82G [00:42<00:01, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  89% 1.75G/1.97G [00:42<00:05, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  98% 1.78G/1.82G [00:43<00:00, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  93% 1.81G/1.95G [00:43<00:03, 40.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  92% 1.77G/1.93G [00:43<00:03, 39.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  89% 1.76G/1.97G [00:43<00:05, 38.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  98% 1.77G/1.82G [00:43<00:01, 34.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  95% 1.82G/1.93G [00:43<00:02, 41.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  98% 1.77G/1.82G [00:43<00:01, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  99% 1.79G/1.82G [00:43<00:00, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  94% 1.82G/1.95G [00:43<00:02, 41.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  92% 1.78G/1.93G [00:43<00:03, 40.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  90% 1.77G/1.97G [00:43<00:04, 39.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  98% 1.78G/1.82G [00:43<00:00, 37.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  89% 1.76G/1.97G [00:43<00:05, 35.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  95% 1.84G/1.93G [00:43<00:02, 41.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  98% 1.78G/1.82G [00:43<00:00, 41.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors:  99% 1.80G/1.82G [00:43<00:00, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  94% 1.84G/1.95G [00:44<00:02, 41.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  93% 1.79G/1.93G [00:43<00:03, 41.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  91% 1.78G/1.97G [00:44<00:04, 40.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  99% 1.79G/1.82G [00:44<00:00, 38.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  96% 1.85G/1.93G [00:44<00:01, 42.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  90% 1.77G/1.97G [00:43<00:05, 34.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  99% 1.79G/1.82G [00:43<00:00, 39.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00005-of-00010.safetensors: 100% 1.81G/1.82G [00:44<00:00, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00005-of-00010.safetensors: 100% 1.82G/1.82G [00:44<00:00, 41.0MB/s]\n",
            "Download complete. Moving file to glm-4-9b-chat/model-00005-of-00010.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  94% 1.80G/1.93G [00:44<00:02, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  91% 1.79G/1.97G [00:44<00:04, 41.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors:  99% 1.80G/1.82G [00:44<00:00, 39.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  96% 1.86G/1.93G [00:44<00:01, 42.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  91% 1.78G/1.97G [00:43<00:05, 36.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors:  99% 1.80G/1.82G [00:43<00:00, 40.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  95% 1.86G/1.95G [00:44<00:02, 42.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  94% 1.81G/1.93G [00:44<00:02, 41.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'model-00009-of-00010.safetensors' to 'glm-4-9b-chat/.cache/huggingface/download/model-00009-of-00010.safetensors.449241babb7ce69a835c121efa26d9fd8823554ed0c8acd2af6666f482dd6809.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  92% 1.80G/1.97G [00:44<00:03, 41.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00010.safetensors: 100% 1.81G/1.82G [00:44<00:00, 40.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00010.safetensors: 100% 1.82G/1.82G [00:44<00:00, 40.7MB/s]\n",
            "Download complete. Moving file to glm-4-9b-chat/model-00002-of-00010.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  91% 1.79G/1.97G [00:44<00:04, 38.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00008-of-00010.safetensors: 100% 1.81G/1.82G [00:44<00:00, 41.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00008-of-00010.safetensors: 100% 1.82G/1.82G [00:44<00:00, 41.0MB/s]\n",
            "Download complete. Moving file to glm-4-9b-chat/model-00008-of-00010.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  95% 1.82G/1.93G [00:44<00:02, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  92% 1.81G/1.97G [00:44<00:03, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   0% 0.00/1.97G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  97% 1.88G/1.93G [00:44<00:01, 42.6MB/s]\u001b[A\u001b[ADownloading 'model-00010-of-00010.safetensors' to 'glm-4-9b-chat/.cache/huggingface/download/model-00010-of-00010.safetensors.2544b92fc4f1cb511b31a6b06021a3136de0705436db6731d30ec5b8a2be80f6.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  92% 1.80G/1.97G [00:44<00:04, 39.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  96% 1.88G/1.95G [00:45<00:01, 42.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  95% 1.84G/1.93G [00:44<00:02, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   1% 10.5M/1.97G [00:00<00:45, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  93% 1.82G/1.97G [00:44<00:03, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'model.safetensors.index.json' to 'glm-4-9b-chat/.cache/huggingface/download/model.safetensors.index.json.7396d4190da53394fe2e654fabbb3085976a1a7a.incomplete'\n",
            "\n",
            "\n",
            "model-00004-of-00010.safetensors:  98% 1.89G/1.93G [00:45<00:00, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:   0% 0.00/1.65G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  92% 1.81G/1.97G [00:44<00:03, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  97% 1.89G/1.95G [00:45<00:01, 42.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  96% 1.85G/1.93G [00:45<00:01, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   1% 21.0M/1.97G [00:00<00:45, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  93% 1.84G/1.97G [00:45<00:03, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors.index.json: 100% 29.1k/29.1k [00:00<00:00, 30.5MB/s]\n",
            "Download complete. Moving file to glm-4-9b-chat/model.safetensors.index.json\n",
            "\n",
            "\n",
            "model-00004-of-00010.safetensors:  98% 1.90G/1.93G [00:45<00:00, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  93% 1.82G/1.97G [00:44<00:03, 41.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   2% 31.5M/1.97G [00:00<00:44, 43.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  96% 1.86G/1.93G [00:45<00:01, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  98% 1.90G/1.95G [00:45<00:01, 42.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  94% 1.85G/1.97G [00:45<00:02, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'modeling_chatglm.py' to 'glm-4-9b-chat/.cache/huggingface/download/modeling_chatglm.py.3b1e503d39ae1dca74ad8aa22f8f14dd2b5c3c42.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:   1% 10.5M/1.65G [00:00<01:10, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors:  99% 1.91G/1.93G [00:45<00:00, 42.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  93% 1.84G/1.97G [00:45<00:03, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   2% 41.9M/1.97G [00:00<00:44, 43.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  97% 1.87G/1.93G [00:45<00:01, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  98% 1.91G/1.95G [00:45<00:00, 42.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  94% 1.86G/1.97G [00:45<00:02, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "modeling_chatglm.py: 100% 47.3k/47.3k [00:00<00:00, 49.6MB/s]\n",
            "Download complete. Moving file to glm-4-9b-chat/modeling_chatglm.py\n",
            "\n",
            "\n",
            "model-00004-of-00010.safetensors: 100% 1.92G/1.93G [00:45<00:00, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  94% 1.85G/1.97G [00:45<00:02, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   3% 52.4M/1.97G [00:01<00:44, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  97% 1.88G/1.93G [00:45<00:01, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  99% 1.92G/1.95G [00:46<00:00, 42.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  95% 1.87G/1.97G [00:45<00:02, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:   1% 21.0M/1.65G [00:00<01:08, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00010.safetensors: 100% 1.93G/1.93G [00:46<00:00, 41.8MB/s]\n",
            "Download complete. Moving file to glm-4-9b-chat/model-00004-of-00010.safetensors\n",
            "Downloading 'tokenization_chatglm.py' to 'glm-4-9b-chat/.cache/huggingface/download/tokenization_chatglm.py.cadd24d098a4b96ca8aa63f593dc88480e79a6c9.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  94% 1.86G/1.97G [00:45<00:02, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   3% 62.9M/1.97G [00:01<00:44, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  98% 1.89G/1.93G [00:46<00:00, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  95% 1.88G/1.97G [00:46<00:02, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors:  99% 1.93G/1.95G [00:46<00:00, 42.1MB/s]\u001b[ADownloading 'tokenizer.model' to 'glm-4-9b-chat/.cache/huggingface/download/tokenizer.model.5a493598071550244b2ee7f26118f3edec2150b9dfa967929a99052ac83fe716.incomplete'\n",
            "\n",
            "\n",
            "tokenization_chatglm.py: 100% 8.99k/8.99k [00:00<00:00, 38.3MB/s]\n",
            "Download complete. Moving file to glm-4-9b-chat/tokenization_chatglm.py\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  95% 1.87G/1.97G [00:45<00:02, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:   2% 31.5M/1.65G [00:01<01:06, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   4% 73.4M/1.97G [00:01<00:43, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  98% 1.90G/1.93G [00:46<00:00, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  96% 1.89G/1.97G [00:46<00:01, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00010.safetensors: 100% 1.94G/1.95G [00:46<00:00, 42.4MB/s]\u001b[A\n",
            "\n",
            "tokenizer.model: 100% 2.62M/2.62M [00:00<00:00, 44.0MB/s]\n",
            "Download complete. Moving file to glm-4-9b-chat/tokenizer.model\n",
            "Downloading 'tokenizer_config.json' to 'glm-4-9b-chat/.cache/huggingface/download/tokenizer_config.json.b35f862ae59230b0504204acb652ef27fa88c1c8.incomplete'\n",
            "\n",
            "model-00001-of-00010.safetensors: 100% 1.95G/1.95G [00:46<00:00, 41.7MB/s]\n",
            "Download complete. Moving file to glm-4-9b-chat/model-00001-of-00010.safetensors\n",
            "Fetching 24 files:  42% 10/24 [00:47<01:33,  6.67s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  95% 1.88G/1.97G [00:46<00:02, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   4% 83.9M/1.97G [00:01<00:43, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors:  99% 1.91G/1.93G [00:46<00:00, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  96% 1.90G/1.97G [00:46<00:01, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "tokenizer_config.json: 100% 6.15k/6.15k [00:00<00:00, 32.6MB/s]\n",
            "Download complete. Moving file to glm-4-9b-chat/tokenizer_config.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:   3% 41.9M/1.65G [00:01<01:06, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  96% 1.89G/1.97G [00:46<00:01, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   5% 94.4M/1.97G [00:02<00:43, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors: 100% 1.92G/1.93G [00:46<00:00, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  97% 1.91G/1.97G [00:46<00:01, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  96% 1.90G/1.97G [00:46<00:01, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00007-of-00010.safetensors: 100% 1.93G/1.93G [00:47<00:00, 40.9MB/s]\n",
            "Download complete. Moving file to glm-4-9b-chat/model-00007-of-00010.safetensors\n",
            "\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   5% 105M/1.97G [00:02<00:43, 43.0MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  97% 1.92G/1.97G [00:47<00:01, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:   3% 52.4M/1.65G [00:02<01:05, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  97% 1.91G/1.97G [00:46<00:01, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   6% 115M/1.97G [00:02<00:42, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  98% 1.93G/1.97G [00:47<00:00, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  97% 1.92G/1.97G [00:47<00:01, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   6% 126M/1.97G [00:02<00:42, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  99% 1.94G/1.97G [00:47<00:00, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:   4% 62.9M/1.65G [00:02<01:04, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  98% 1.93G/1.97G [00:47<00:00, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   7% 136M/1.97G [00:03<00:42, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors:  99% 1.95G/1.97G [00:47<00:00, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors:  99% 1.94G/1.97G [00:47<00:00, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:   4% 73.4M/1.65G [00:03<01:04, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   7% 147M/1.97G [00:03<00:42, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors: 100% 1.96G/1.97G [00:48<00:00, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors: 100% 1.97G/1.97G [00:48<00:00, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00006-of-00010.safetensors: 100% 1.97G/1.97G [00:48<00:00, 40.7MB/s]\n",
            "Download complete. Moving file to glm-4-9b-chat/model-00006-of-00010.safetensors\n",
            "\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   8% 157M/1.97G [00:03<00:41, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:   5% 83.9M/1.65G [00:03<01:04, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors: 100% 1.96G/1.97G [00:48<00:00, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   9% 168M/1.97G [00:03<00:41, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00003-of-00010.safetensors: 100% 1.97G/1.97G [00:48<00:00, 40.8MB/s]\n",
            "Download complete. Moving file to glm-4-9b-chat/model-00003-of-00010.safetensors\n",
            "Fetching 24 files:  50% 12/24 [00:49<01:00,  5.06s/it]\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:   9% 178M/1.97G [00:04<00:41, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:   6% 94.4M/1.65G [00:03<01:03, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  10% 189M/1.97G [00:04<00:41, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  10% 199M/1.97G [00:04<00:40, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:   6% 105M/1.65G [00:04<01:02, 24.7MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  11% 210M/1.97G [00:04<00:40, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:   7% 115M/1.65G [00:04<01:02, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  11% 220M/1.97G [00:05<00:40, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  12% 231M/1.97G [00:05<00:40, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:   8% 126M/1.65G [00:05<01:02, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  12% 241M/1.97G [00:05<00:39, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  13% 252M/1.97G [00:05<00:39, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:   8% 136M/1.65G [00:05<01:01, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  13% 262M/1.97G [00:06<00:39, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  14% 273M/1.97G [00:06<00:39, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:   9% 147M/1.65G [00:05<01:00, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  14% 283M/1.97G [00:06<00:38, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  15% 294M/1.97G [00:06<00:38, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  10% 157M/1.65G [00:06<01:00, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  15% 304M/1.97G [00:07<00:38, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  10% 168M/1.65G [00:06<00:59, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  16% 315M/1.97G [00:07<00:38, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  17% 325M/1.97G [00:07<00:38, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  11% 178M/1.65G [00:07<00:59, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  17% 336M/1.97G [00:07<00:37, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  18% 346M/1.97G [00:08<00:37, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  11% 189M/1.65G [00:07<00:59, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  18% 357M/1.97G [00:08<00:37, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  19% 367M/1.97G [00:08<00:36, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  12% 199M/1.65G [00:08<00:58, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  19% 377M/1.97G [00:08<00:37, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  13% 210M/1.65G [00:08<00:58, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  20% 388M/1.97G [00:08<00:36, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  20% 398M/1.97G [00:09<00:36, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  13% 220M/1.65G [00:08<00:58, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  21% 409M/1.97G [00:09<00:36, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  21% 419M/1.97G [00:09<00:35, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  14% 231M/1.65G [00:09<00:57, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  22% 430M/1.97G [00:09<00:35, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  15% 241M/1.65G [00:09<00:57, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  22% 440M/1.97G [00:10<00:35, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  23% 451M/1.97G [00:10<00:36, 41.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  15% 252M/1.65G [00:10<00:58, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  23% 461M/1.97G [00:10<00:37, 40.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  24% 472M/1.97G [00:10<00:36, 41.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  16% 262M/1.65G [00:10<00:56, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  25% 482M/1.97G [00:11<00:35, 41.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  25% 493M/1.97G [00:11<00:34, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  17% 273M/1.65G [00:11<00:59, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  26% 503M/1.97G [00:11<00:34, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  26% 514M/1.97G [00:11<00:34, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  17% 283M/1.65G [00:11<00:57, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  27% 524M/1.97G [00:12<00:33, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  18% 294M/1.65G [00:12<00:56, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  27% 535M/1.97G [00:12<00:33, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  28% 545M/1.97G [00:12<00:33, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  18% 304M/1.65G [00:12<00:55, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  28% 556M/1.97G [00:12<00:32, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  29% 566M/1.97G [00:13<00:32, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  19% 315M/1.65G [00:12<00:54, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  29% 577M/1.97G [00:13<00:32, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  30% 587M/1.97G [00:13<00:32, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  20% 325M/1.65G [00:13<00:54, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  30% 598M/1.97G [00:13<00:32, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  20% 336M/1.65G [00:13<00:53, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  31% 608M/1.97G [00:14<00:31, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  31% 619M/1.97G [00:14<00:32, 42.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  21% 346M/1.65G [00:14<00:53, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  32% 629M/1.97G [00:14<00:31, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  32% 640M/1.97G [00:14<00:31, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  22% 357M/1.65G [00:14<00:52, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  33% 650M/1.97G [00:15<00:30, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  34% 661M/1.97G [00:15<00:30, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  22% 367M/1.65G [00:15<00:52, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  34% 671M/1.97G [00:15<00:30, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  23% 377M/1.65G [00:15<00:51, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  35% 682M/1.97G [00:15<00:29, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  35% 692M/1.97G [00:16<00:29, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  24% 388M/1.65G [00:15<00:51, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  36% 703M/1.97G [00:16<00:29, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  36% 713M/1.97G [00:16<00:29, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  24% 398M/1.65G [00:16<00:50, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  37% 724M/1.97G [00:16<00:29, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  25% 409M/1.65G [00:16<00:50, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  37% 734M/1.97G [00:17<00:28, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  38% 744M/1.97G [00:17<00:28, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  25% 419M/1.65G [00:17<00:49, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  38% 755M/1.97G [00:17<00:28, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  39% 765M/1.97G [00:17<00:28, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  26% 430M/1.65G [00:17<00:49, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  39% 776M/1.97G [00:18<00:27, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  40% 786M/1.97G [00:18<00:27, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  27% 440M/1.65G [00:18<00:49, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  40% 797M/1.97G [00:18<00:27, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  27% 451M/1.65G [00:18<00:48, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  41% 807M/1.97G [00:18<00:26, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  42% 818M/1.97G [00:19<00:26, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  28% 461M/1.65G [00:18<00:48, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  42% 828M/1.97G [00:19<00:26, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  43% 839M/1.97G [00:19<00:26, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  29% 472M/1.65G [00:19<00:47, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  43% 849M/1.97G [00:19<00:26, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  44% 860M/1.97G [00:20<00:25, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  29% 482M/1.65G [00:19<00:47, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  44% 870M/1.97G [00:20<00:25, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  30% 493M/1.65G [00:20<00:47, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  45% 881M/1.97G [00:20<00:25, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  45% 891M/1.97G [00:20<00:25, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  31% 503M/1.65G [00:20<00:46, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  46% 902M/1.97G [00:21<00:25, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  46% 912M/1.97G [00:21<00:25, 41.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  31% 514M/1.65G [00:21<00:48, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  47% 923M/1.97G [00:21<00:24, 41.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  47% 933M/1.97G [00:21<00:24, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  32% 524M/1.65G [00:21<00:45, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  48% 944M/1.97G [00:22<00:24, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  32% 535M/1.65G [00:21<00:44, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  48% 954M/1.97G [00:22<00:23, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  49% 965M/1.97G [00:22<00:23, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  33% 545M/1.65G [00:22<00:44, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  50% 975M/1.97G [00:22<00:23, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  50% 986M/1.97G [00:22<00:22, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  34% 556M/1.65G [00:22<00:44, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  51% 996M/1.97G [00:23<00:22, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  51% 1.01G/1.97G [00:23<00:22, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  34% 566M/1.65G [00:23<00:44, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  52% 1.02G/1.97G [00:23<00:21, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  35% 577M/1.65G [00:23<00:43, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  52% 1.03G/1.97G [00:23<00:21, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  53% 1.04G/1.97G [00:24<00:21, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  36% 587M/1.65G [00:23<00:43, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  53% 1.05G/1.97G [00:24<00:21, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  54% 1.06G/1.97G [00:24<00:21, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  36% 598M/1.65G [00:24<00:42, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  54% 1.07G/1.97G [00:24<00:20, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  55% 1.08G/1.97G [00:25<00:20, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  37% 608M/1.65G [00:24<00:42, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  55% 1.09G/1.97G [00:25<00:20, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  38% 619M/1.65G [00:25<00:41, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  56% 1.10G/1.97G [00:25<00:20, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  56% 1.11G/1.97G [00:25<00:20, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  38% 629M/1.65G [00:25<00:43, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  57% 1.12G/1.97G [00:26<00:19, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  58% 1.13G/1.97G [00:26<00:19, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  39% 640M/1.65G [00:26<00:42, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  58% 1.14G/1.97G [00:26<00:19, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  59% 1.15G/1.97G [00:26<00:19, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  39% 650M/1.65G [00:26<00:41, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  59% 1.16G/1.97G [00:27<00:18, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  60% 1.17G/1.97G [00:27<00:19, 41.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  40% 661M/1.65G [00:27<00:41, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  60% 1.18G/1.97G [00:27<00:18, 41.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  41% 671M/1.65G [00:27<00:40, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  61% 1.20G/1.97G [00:27<00:19, 39.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  61% 1.21G/1.97G [00:28<00:19, 39.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  41% 682M/1.65G [00:27<00:39, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  62% 1.22G/1.97G [00:28<00:18, 40.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  62% 1.23G/1.97G [00:28<00:18, 41.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  42% 692M/1.65G [00:28<00:39, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  63% 1.24G/1.97G [00:29<00:18, 39.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  43% 703M/1.65G [00:28<00:38, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  63% 1.25G/1.97G [00:29<00:17, 40.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  64% 1.26G/1.97G [00:29<00:17, 40.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  43% 713M/1.65G [00:29<00:38, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  64% 1.27G/1.97G [00:29<00:16, 41.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  44% 724M/1.65G [00:29<00:37, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  65% 1.28G/1.97G [00:29<00:16, 41.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  66% 1.29G/1.97G [00:30<00:16, 42.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  45% 734M/1.65G [00:30<00:37, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  66% 1.30G/1.97G [00:30<00:15, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  67% 1.31G/1.97G [00:30<00:15, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  45% 744M/1.65G [00:30<00:36, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  67% 1.32G/1.97G [00:30<00:15, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  68% 1.33G/1.97G [00:31<00:14, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  46% 755M/1.65G [00:30<00:36, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  68% 1.34G/1.97G [00:31<00:14, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  46% 765M/1.65G [00:31<00:36, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  69% 1.35G/1.97G [00:31<00:14, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  69% 1.36G/1.97G [00:31<00:14, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  47% 776M/1.65G [00:31<00:35, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  70% 1.37G/1.97G [00:32<00:14, 41.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  48% 786M/1.65G [00:32<00:34, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  70% 1.38G/1.97G [00:32<00:15, 38.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  71% 1.39G/1.97G [00:32<00:14, 39.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  48% 797M/1.65G [00:32<00:34, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  71% 1.41G/1.97G [00:33<00:14, 39.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  72% 1.42G/1.97G [00:33<00:13, 40.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  49% 807M/1.65G [00:33<00:34, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  72% 1.43G/1.97G [00:33<00:13, 41.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  73% 1.44G/1.97G [00:33<00:12, 42.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  50% 818M/1.65G [00:33<00:33, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  74% 1.45G/1.97G [00:34<00:12, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  50% 828M/1.65G [00:33<00:33, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  74% 1.46G/1.97G [00:34<00:12, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  75% 1.47G/1.97G [00:34<00:11, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  51% 839M/1.65G [00:34<00:32, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  75% 1.48G/1.97G [00:34<00:11, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  76% 1.49G/1.97G [00:35<00:11, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  51% 849M/1.65G [00:34<00:32, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  76% 1.50G/1.97G [00:35<00:11, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  77% 1.51G/1.97G [00:35<00:10, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  52% 860M/1.65G [00:35<00:32, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  77% 1.52G/1.97G [00:35<00:10, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  53% 870M/1.65G [00:35<00:31, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  78% 1.53G/1.97G [00:36<00:10, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  78% 1.54G/1.97G [00:36<00:10, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  53% 881M/1.65G [00:36<00:31, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  79% 1.55G/1.97G [00:36<00:09, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  54% 891M/1.65G [00:36<00:30, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  79% 1.56G/1.97G [00:36<00:11, 36.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  80% 1.57G/1.97G [00:37<00:10, 37.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  55% 902M/1.65G [00:36<00:30, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  80% 1.58G/1.97G [00:37<00:10, 38.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  55% 912M/1.65G [00:37<00:29, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  81% 1.59G/1.97G [00:37<00:09, 39.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  82% 1.60G/1.97G [00:37<00:09, 40.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  56% 923M/1.65G [00:37<00:29, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  82% 1.61G/1.97G [00:38<00:08, 40.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  83% 1.63G/1.97G [00:38<00:08, 41.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  57% 933M/1.65G [00:38<00:29, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  83% 1.64G/1.97G [00:38<00:08, 41.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  84% 1.65G/1.97G [00:38<00:07, 41.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  57% 944M/1.65G [00:38<00:28, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  84% 1.66G/1.97G [00:39<00:07, 41.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  58% 954M/1.65G [00:38<00:28, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  85% 1.67G/1.97G [00:39<00:07, 41.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  85% 1.68G/1.97G [00:39<00:07, 39.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  58% 965M/1.65G [00:39<00:27, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  86% 1.69G/1.97G [00:39<00:06, 40.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  86% 1.70G/1.97G [00:40<00:06, 41.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  59% 975M/1.65G [00:39<00:27, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  87% 1.71G/1.97G [00:40<00:06, 41.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  60% 986M/1.65G [00:40<00:26, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  87% 1.72G/1.97G [00:40<00:05, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  88% 1.73G/1.97G [00:40<00:05, 42.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  60% 996M/1.65G [00:40<00:26, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  88% 1.74G/1.97G [00:41<00:05, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  89% 1.75G/1.97G [00:41<00:05, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  61% 1.01G/1.65G [00:41<00:25, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  89% 1.76G/1.97G [00:41<00:04, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  90% 1.77G/1.97G [00:41<00:04, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  62% 1.02G/1.65G [00:41<00:25, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  91% 1.78G/1.97G [00:42<00:04, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  62% 1.03G/1.65G [00:41<00:25, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  91% 1.79G/1.97G [00:42<00:04, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  92% 1.80G/1.97G [00:42<00:03, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  63% 1.04G/1.65G [00:42<00:24, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  92% 1.81G/1.97G [00:42<00:03, 39.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  64% 1.05G/1.65G [00:42<00:24, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  93% 1.82G/1.97G [00:43<00:03, 38.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  93% 1.84G/1.97G [00:43<00:03, 36.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  64% 1.06G/1.65G [00:43<00:24, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  94% 1.85G/1.97G [00:43<00:03, 38.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  94% 1.86G/1.97G [00:44<00:02, 39.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  65% 1.07G/1.65G [00:43<00:24, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  95% 1.87G/1.97G [00:44<00:02, 40.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  65% 1.08G/1.65G [00:44<00:23, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  95% 1.88G/1.97G [00:44<00:02, 40.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  96% 1.89G/1.97G [00:44<00:01, 40.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  66% 1.09G/1.65G [00:44<00:23, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  96% 1.90G/1.97G [00:45<00:01, 41.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  97% 1.91G/1.97G [00:45<00:01, 41.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  67% 1.10G/1.65G [00:45<00:22, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  97% 1.92G/1.97G [00:45<00:01, 41.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  67% 1.11G/1.65G [00:45<00:22, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  98% 1.93G/1.97G [00:45<00:01, 37.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  99% 1.94G/1.97G [00:46<00:00, 38.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  68% 1.12G/1.65G [00:45<00:21, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors:  99% 1.95G/1.97G [00:46<00:00, 39.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors: 100% 1.96G/1.97G [00:46<00:00, 40.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  69% 1.13G/1.65G [00:46<00:21, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00009-of-00010.safetensors: 100% 1.97G/1.97G [00:46<00:00, 42.0MB/s]\n",
            "Download complete. Moving file to glm-4-9b-chat/model-00009-of-00010.safetensors\n",
            "Fetching 24 files:  75% 18/24 [01:32<00:37,  6.21s/it]\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  69% 1.14G/1.65G [00:46<00:20, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  70% 1.15G/1.65G [00:47<00:20, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  71% 1.16G/1.65G [00:47<00:19, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  71% 1.17G/1.65G [00:48<00:19, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  72% 1.18G/1.65G [00:48<00:18, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  72% 1.20G/1.65G [00:48<00:18, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  73% 1.21G/1.65G [00:49<00:18, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  74% 1.22G/1.65G [00:49<00:17, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  74% 1.23G/1.65G [00:50<00:17, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  75% 1.24G/1.65G [00:50<00:16, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  76% 1.25G/1.65G [00:51<00:16, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  76% 1.26G/1.65G [00:51<00:15, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  77% 1.27G/1.65G [00:51<00:15, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  78% 1.28G/1.65G [00:52<00:15, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  78% 1.29G/1.65G [00:52<00:14, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  79% 1.30G/1.65G [00:53<00:14, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  79% 1.31G/1.65G [00:53<00:13, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  80% 1.32G/1.65G [00:53<00:13, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  81% 1.33G/1.65G [00:54<00:12, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  81% 1.34G/1.65G [00:54<00:12, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  82% 1.35G/1.65G [00:55<00:12, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  83% 1.36G/1.65G [00:55<00:11, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  83% 1.37G/1.65G [00:56<00:11, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  84% 1.38G/1.65G [00:56<00:10, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  85% 1.39G/1.65G [00:57<00:10, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  85% 1.41G/1.65G [00:57<00:10, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  86% 1.42G/1.65G [00:57<00:09, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  86% 1.43G/1.65G [00:58<00:09, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  87% 1.44G/1.65G [00:58<00:08, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  88% 1.45G/1.65G [00:59<00:08, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  88% 1.46G/1.65G [00:59<00:07, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  89% 1.47G/1.65G [01:00<00:07, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  90% 1.48G/1.65G [01:00<00:06, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  90% 1.49G/1.65G [01:00<00:06, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  91% 1.50G/1.65G [01:01<00:06, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  92% 1.51G/1.65G [01:01<00:05, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  92% 1.52G/1.65G [01:02<00:05, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  93% 1.53G/1.65G [01:02<00:04, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  93% 1.54G/1.65G [01:03<00:04, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  94% 1.55G/1.65G [01:03<00:03, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  95% 1.56G/1.65G [01:03<00:03, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  95% 1.57G/1.65G [01:04<00:03, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  96% 1.58G/1.65G [01:04<00:02, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  97% 1.59G/1.65G [01:05<00:02, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  97% 1.60G/1.65G [01:05<00:01, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  98% 1.61G/1.65G [01:06<00:01, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  99% 1.63G/1.65G [01:06<00:00, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors:  99% 1.64G/1.65G [01:06<00:00, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors: 100% 1.65G/1.65G [01:07<00:00, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00010-of-00010.safetensors: 100% 1.65G/1.65G [01:07<00:00, 24.5MB/s]\n",
            "Download complete. Moving file to glm-4-9b-chat/model-00010-of-00010.safetensors\n",
            "Fetching 24 files: 100% 24/24 [01:53<00:00,  4.74s/it]\n",
            "/content/llama.cpp/glm-4-9b-chat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n",
        "\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS62KVJUtHQk",
        "outputId": "8fc6564b-fd06-430b-8ba2-2a1be2cff6b7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: numpy~=1.26.4 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements-convert_legacy_llama.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: sentencepiece~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements-convert_legacy_llama.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.45.1 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (4.46.2)\n",
            "Requirement already satisfied: gguf>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements-convert_legacy_llama.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.21.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements-convert_legacy_llama.txt (line 5)) (4.25.5)\n",
            "Collecting torch~=2.2.1 (from -r ./requirements/requirements-convert_hf_to_gguf.txt (line 3))\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.2.2%2Bcpu-cp310-cp310-linux_x86_64.whl (186.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.8/186.8 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (0.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch~=2.2.1->-r ./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch~=2.2.1->-r ./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch~=2.2.1->-r ./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch~=2.2.1->-r ./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch~=2.2.1->-r ./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (2024.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch~=2.2.1->-r ./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.45.1->-r ./requirements/requirements-convert_legacy_llama.txt (line 3)) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch~=2.2.1->-r ./requirements/requirements-convert_hf_to_gguf.txt (line 3)) (1.3.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.0\n",
            "    Uninstalling torch-2.4.0:\n",
            "      Successfully uninstalled torch-2.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.2.2+cpu which is incompatible.\n",
            "torchvision 0.19.0 requires torch==2.4.0, but you have torch 2.2.2+cpu which is incompatible.\n",
            "vllm 0.6.3.post1 requires torch==2.4.0, but you have torch 2.2.2+cpu which is incompatible.\n",
            "xformers 0.0.27.post2 requires torch==2.4.0, but you have torch 2.2.2+cpu which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.2.2+cpu\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 convert_hf_to_gguf.py ./glm-4-9b-chat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mh5AqA3tNFN",
        "outputId": "e8add088-a1b5-4c40-8542-e9c798f087d5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:hf-to-gguf:Loading model: glm-4-9b-chat\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00010.safetensors'\n",
            "INFO:hf-to-gguf:token_embd.weight,         torch.bfloat16 --> F16, shape = {4096, 151552}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,     torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,       torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_qkv.bias,       torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.0.attn_qkv.weight,     torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,       torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_qkv.bias,       torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.1.attn_qkv.weight,     torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00010.safetensors'\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,     torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,     torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,       torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_qkv.bias,       torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.2.attn_qkv.weight,     torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,     torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,       torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_qkv.bias,       torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.3.attn_qkv.weight,     torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,     torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,       torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_qkv.bias,       torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.4.attn_qkv.weight,     torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,     torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,       torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_qkv.bias,       torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.5.attn_qkv.weight,     torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_qkv.bias,       torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.6.attn_qkv.weight,     torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00010.safetensors'\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.10.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,     torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,       torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,     torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,       torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_qkv.bias,       torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.7.attn_qkv.weight,     torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,     torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,       torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_qkv.bias,       torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.8.attn_qkv.weight,     torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,     torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,       torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,  torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_qkv.bias,       torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.9.attn_qkv.weight,     torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00010.safetensors'\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.11.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.12.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.13.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.14.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.15.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00005-of-00010.safetensors'\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.16.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.17.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.18.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.19.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.20.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00006-of-00010.safetensors'\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.21.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.22.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.23.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.24.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00007-of-00010.safetensors'\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.25.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.26.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.27.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.28.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.29.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00008-of-00010.safetensors'\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.30.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.31.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.32.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.32.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.32.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.32.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.32.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.32.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.32.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.33.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.33.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.33.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.33.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.33.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.33.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.33.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.34.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.34.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.34.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.34.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.34.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00009-of-00010.safetensors'\n",
            "INFO:hf-to-gguf:blk.34.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.34.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.35.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.35.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.35.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.35.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.35.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.35.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.35.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.36.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.36.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.36.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.36.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.36.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.36.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.36.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.37.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.37.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.37.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.37.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.37.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.37.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.37.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.38.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.38.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.38.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.38.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.38.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.38.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.38.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:blk.39.attn_norm.weight,   torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00010-of-00010.safetensors'\n",
            "INFO:hf-to-gguf:output_norm.weight,        torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.39.ffn_down.weight,    torch.bfloat16 --> F16, shape = {13696, 4096}\n",
            "INFO:hf-to-gguf:blk.39.ffn_up.weight,      torch.bfloat16 --> F16, shape = {4096, 27392}\n",
            "INFO:hf-to-gguf:blk.39.ffn_norm.weight,    torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.39.attn_output.weight, torch.bfloat16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.39.attn_qkv.bias,      torch.bfloat16 --> F32, shape = {4608}\n",
            "INFO:hf-to-gguf:blk.39.attn_qkv.weight,    torch.bfloat16 --> F16, shape = {4096, 4608}\n",
            "INFO:hf-to-gguf:output.weight,             torch.bfloat16 --> F16, shape = {4096, 151552}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Adding 151073 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type pad to 151329\n",
            "INFO:gguf.vocab:Setting special token type eos to 151329\n",
            "INFO:gguf.vocab:Setting special token type eot to 151336\n",
            "INFO:gguf.vocab:Setting special token type unk to 151329\n",
            "INFO:gguf.vocab:Setting chat_template to [gMASK]<sop>{% for item in messages %}{% if item['tools'] is defined %}<|system|>\n",
            "你是一个名为 ChatGLM 的人工智能助手。你是基于智谱AI训练的语言模型 GLM-4 模型开发的，你的任务是针对用户的问题和要求提供适当的答复和支持。\n",
            "\n",
            "# 可用工具{% set tools = item['tools'] %}{% for tool in tools %}{% if tool['type'] == 'function' %}\n",
            "\n",
            "## {{ tool['function']['name'] }}\n",
            "\n",
            "{{ tool['function'] | tojson(indent=4) }}\n",
            "在调用上述函数时，请使用 Json 格式表示调用的参数。{% elif tool['type'] == 'python' %}\n",
            "\n",
            "## python\n",
            "\n",
            "当你向 `python` 发送包含 Python 代码的消息时，该代码将会在一个有状态的 Jupyter notebook 环境中执行。\n",
            "`python` 返回代码执行的输出，或在执行 60 秒后返回超时。\n",
            "`/mnt/data` 将会持久化存储你的文件。在此会话中，`python` 无法访问互联网。不要使用 `python` 进行任何网络请求或者在线 API 调用，这些在线内容的访问将不会成功。{% elif tool['type'] == 'simple_browser' %}\n",
            "\n",
            "## simple_browser\n",
            "\n",
            "你可以使用 `simple_browser` 工具。该工具支持以下函数：\n",
            "`search(query: str, recency_days: int)`：使用搜索引擎进行查询并显示结果，可以使用 `recency_days` 参数控制搜索内容的时效性。\n",
            "`mclick(ids: list[int])`：获取一系列指定 id 的页面内容。每次调用时，须选择3-10个页面。选择多个角度的页面，同时尽可能选择可信任的信息来源。考虑到部分页面是无法加载的，你也可以多打开一些可能有用的页面而不用担心内容过多。\n",
            "`open_url(url: str)`：打开指定的 URL。\n",
            "\n",
            "使用 `【{引用 id}†{引用文本}】` 来引用内容。\n",
            "\n",
            "操作步骤：1. 使用 `search` 来获得信息列表; 2. 使用 `mclick` 来获取指定 ID 页面的内容; 3. 根据获得的内容进行回复。在回复中应当引用信息来源。\n",
            " 如果用户提供了 URL，也可以用 `open_url` 直接打开页面。\n",
            "如果初次搜索结果没有找到合适的信息，也可以再次使用 `search` 进行搜索。{% elif tool['type'] == 'cogview' %}\n",
            "\n",
            "## cogview\n",
            "\n",
            "如果用户的请求中包含了对图像的描述，你可以使用 `cogview` 来生成图像并展示给用户。你需要向 `cogview` 发送图像描述，规则：\n",
            "- 发送给 `cogview` 的消息必须使用英语。用户的中文描述必须完全翻译为英语。\n",
            "- 应当尽可能详细地描述图像生成的需求，需求描述约 100 英文单词。\n",
            "- 保持用户原始描述的意图。不要虚构内容或者没见过的人物。\n",
            "- 如无特殊说明，所在地为中国，持有中国立场并遵循中国社会主义价值观。{% endif %}{% endfor %}{% endif %}{% if item['content'] %}<|{{ item['role'] }}|>{{ item['metadata'] }}\n",
            "{{ item['content'] }}{% endif %}{% endfor %}{% if add_generation_prompt %}<|assistant|>{% endif %}\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:glm-4-9b-chat/glm-4-9B-chat-F16.gguf: n_tensors = 283, total_size = 18.8G\n",
            "Writing: 100% 18.8G/18.8G [01:17<00:00, 242Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to glm-4-9b-chat/glm-4-9B-chat-F16.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l -h ./glm-4-9b-chat/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzWFq_fytPq7",
        "outputId": "24150f83-3270-4a5d-85a1-7c49b7e190c3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 36G\n",
            "-rw-r--r-- 1 root root 1.5K Nov 13 18:05 config.json\n",
            "-rw-r--r-- 1 root root 2.3K Nov 13 18:05 configuration_chatglm.py\n",
            "-rw-r--r-- 1 root root   36 Nov 13 18:05 configuration.json\n",
            "-rw-r--r-- 1 root root  207 Nov 13 18:05 generation_config.json\n",
            "-rw-r--r-- 1 root root  18G Nov 13 18:09 glm-4-9B-chat-F16.gguf\n",
            "-rw-r--r-- 1 root root 6.4K Nov 13 18:05 LICENSE\n",
            "-rw-r--r-- 1 root root 1.9G Nov 13 18:06 model-00001-of-00010.safetensors\n",
            "-rw-r--r-- 1 root root 1.7G Nov 13 18:06 model-00002-of-00010.safetensors\n",
            "-rw-r--r-- 1 root root 1.9G Nov 13 18:06 model-00003-of-00010.safetensors\n",
            "-rw-r--r-- 1 root root 1.8G Nov 13 18:06 model-00004-of-00010.safetensors\n",
            "-rw-r--r-- 1 root root 1.7G Nov 13 18:06 model-00005-of-00010.safetensors\n",
            "-rw-r--r-- 1 root root 1.9G Nov 13 18:06 model-00006-of-00010.safetensors\n",
            "-rw-r--r-- 1 root root 1.8G Nov 13 18:06 model-00007-of-00010.safetensors\n",
            "-rw-r--r-- 1 root root 1.7G Nov 13 18:06 model-00008-of-00010.safetensors\n",
            "-rw-r--r-- 1 root root 1.9G Nov 13 18:07 model-00009-of-00010.safetensors\n",
            "-rw-r--r-- 1 root root 1.6G Nov 13 18:07 model-00010-of-00010.safetensors\n",
            "-rw-r--r-- 1 root root  47K Nov 13 18:06 modeling_chatglm.py\n",
            "-rw-r--r-- 1 root root  29K Nov 13 18:06 model.safetensors.index.json\n",
            "-rw-r--r-- 1 root root 9.3K Nov 13 18:05 README_en.md\n",
            "-rw-r--r-- 1 root root 8.6K Nov 13 18:05 README.md\n",
            "-rw-r--r-- 1 root root 8.8K Nov 13 18:06 tokenization_chatglm.py\n",
            "-rw-r--r-- 1 root root 6.1K Nov 13 18:06 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root 2.6M Nov 13 18:06 tokenizer.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ollama 推理"
      ],
      "metadata": {
        "id": "SDAU0MvStpJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qz8JMMctpxj",
        "outputId": "a3359a6c-2565-41ec-b91b-a9781d135612"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "############################################################################################# 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve > ollama.out 2>&1 &"
      ],
      "metadata": {
        "id": "RoZlVoiXuVEr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull qwen2:0.5b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NemfQo0wlUv",
        "outputId": "2fa1e5d9-eae0-4345-ac88-013673bfb74f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...   0% ▕▏    0 B/352 MB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...   0% ▕▏    0 B/352 MB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...   0% ▕▏    0 B/352 MB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...   0% ▕▏    0 B/352 MB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...   0% ▕▏    0 B/352 MB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...   0% ▕▏    0 B/352 MB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...   0% ▕▏    0 B/352 MB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...   1% ▕▏ 5.3 MB/352 MB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...   6% ▕▏  19 MB/352 MB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...  15% ▕▏  54 MB/352 MB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...  23% ▕▏  81 MB/352 MB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...  38% ▕▏ 134 MB/352 MB  109 MB/s      1s\u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...  50% ▕▏ 175 MB/352 MB  109 MB/s      1s\u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...  56% ▕▏ 195 MB/352 MB  109 MB/s      1s\u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...  67% ▕▏ 235 MB/352 MB  109 MB/s      1s\u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...  76% ▕▏ 268 MB/352 MB  109 MB/s      0s\u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...  82% ▕▏ 288 MB/352 MB  109 MB/s      0s\u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...  88% ▕▏ 308 MB/352 MB  109 MB/s      0s\u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...  94% ▕▏ 331 MB/352 MB  109 MB/s      0s\u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4...  97% ▕▏ 340 MB/352 MB  109 MB/s      0s\u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093...   0% ▕▏    0 B/ 182 B                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093...   0% ▕▏    0 B/ 182 B                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093...   0% ▕▏    0 B/ 182 B                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093...   0% ▕▏    0 B/ 182 B                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e...   0% ▕▏    0 B/ 11 KB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e...   0% ▕▏    0 B/ 11 KB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e...   0% ▕▏    0 B/ 11 KB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e...   0% ▕▏    0 B/ 11 KB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e...   0% ▕▏    0 B/ 11 KB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e...   0% ▕▏    0 B/ 11 KB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e...   0% ▕▏    0 B/ 11 KB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e...   0% ▕▏    0 B/ 11 KB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e...   0% ▕▏    0 B/ 11 KB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e...   0% ▕▏    0 B/ 11 KB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e...   0% ▕▏    0 B/ 11 KB                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242...   0% ▕▏    0 B/  59 B                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242...   0% ▕▏    0 B/  59 B                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242...   0% ▕▏    0 B/  59 B                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242...   0% ▕▏    0 B/  59 B                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242...   0% ▕▏    0 B/  59 B                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b...   0% ▕▏    0 B/ 488 B                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b...   0% ▕▏    0 B/ 488 B                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b...   0% ▕▏    0 B/ 488 B                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b...   0% ▕▏    0 B/ 488 B                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b...   0% ▕▏    0 B/ 488 B                  \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \n",
            "verifying sha256 digest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \n",
            "verifying sha256 digest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \n",
            "verifying sha256 digest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \n",
            "verifying sha256 digest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \n",
            "verifying sha256 digest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \n",
            "verifying sha256 digest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \n",
            "verifying sha256 digest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \n",
            "verifying sha256 digest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \n",
            "verifying sha256 digest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \n",
            "verifying sha256 digest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \n",
            "verifying sha256 digest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 8de95da68dc4... 100% ▕▏ 352 MB                         \n",
            "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
            "pulling c156170b718e... 100% ▕▏  11 KB                         \n",
            "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
            "pulling 2184ab82477b... 100% ▕▏  488 B                         \n",
            "verifying sha256 digest \n",
            "writing manifest \n",
            "success \u001b[?25h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV_vkOCYwpc-",
        "outputId": "5dfeca1c-9b6b-428e-c348-75121e174087"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "# Set OpenAI's API key and API base to use vLLM's API server.\n",
        "openai_api_key = \"EMPTY\"\n",
        "openai_api_base = \"http://localhost:11434/v1\"\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=openai_api_key,\n",
        "    base_url=openai_api_base,\n",
        ")\n",
        "\n",
        "chat_response = client.chat.completions.create(\n",
        "    model=\"qwen2:0.5b\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Tell me something about large language models.\"},\n",
        "    ]\n",
        ")\n",
        "print(\"Chat response:\", chat_response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTEe57FAwwYY",
        "outputId": "414506b1-1266-481b-b2b5-7c1fb78d6f21"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chat response: As an artificial intelligence, I don't have personal beliefs or opinions; however, there is plenty of available information which should help you understand larger language models.\n",
            "\n",
            "Understanding these complex ideas can be daunting, but there's a lot more to know if you want to be as accurate as possible when answering questions.\n",
            "\n",
            "One very important component is how large language models work. Typically, these systems calculate natural language inputs based on existing data and the probability distribution of words in that data set. The goal of this process often involves deep learning techniques like RNNs (recurrent neural networks) or Transformer models which use various types of non-linearities to analyze patterns in language.\n",
            "\n",
            "If you have an algorithm or a method, name it, then people can easily calculate the output for any input and compare that output with each other. This gives rise to what physicists call the Belief Propagation Problem — this is an interesting mathematical problem but it's one that many experts regard as highly non-trivial despite having a formal answer in principle.\n",
            "\n",
            "Research and development of these systems has grown through extensive scientific and engineering efforts since the pioneering work on language modeling by Donald L. Kruskal at MIT from 1970 to 1973. There's a lot more to look forward to if you have any interest in this particular area!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# litellm 代理"
      ],
      "metadata": {
        "id": "w0QU1iWWwxiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'litellm[proxy]'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERtz6mbxw0kB",
        "outputId": "97aab78c-5f22-49a7-8257-c82cf7c74e57"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting litellm[proxy]\n",
            "  Downloading litellm-1.52.6-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from litellm[proxy]) (3.10.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from litellm[proxy]) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm[proxy]) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from litellm[proxy]) (3.1.4)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm[proxy]) (4.23.0)\n",
            "Requirement already satisfied: openai>=1.54.0 in /usr/local/lib/python3.10/dist-packages (from litellm[proxy]) (1.54.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from litellm[proxy]) (2.9.2)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from litellm[proxy]) (1.0.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from litellm[proxy]) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from litellm[proxy]) (0.7.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm[proxy]) (0.20.3)\n",
            "Requirement already satisfied: PyJWT<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm[proxy]) (2.9.0)\n",
            "Collecting apscheduler<4.0.0,>=3.10.4 (from litellm[proxy])\n",
            "  Downloading APScheduler-3.10.4-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting backoff (from litellm[proxy])\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting cryptography<43.0.0,>=42.0.5 (from litellm[proxy])\n",
            "  Downloading cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting fastapi<0.112.0,>=0.111.0 (from litellm[proxy])\n",
            "  Downloading fastapi-0.111.1-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting fastapi-sso<0.11.0,>=0.10.0 (from litellm[proxy])\n",
            "  Downloading fastapi_sso-0.10.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting gunicorn<23.0.0,>=22.0.0 (from litellm[proxy])\n",
            "  Downloading gunicorn-22.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from litellm[proxy]) (3.10.11)\n",
            "Collecting pynacl<2.0.0,>=1.5.0 (from litellm[proxy])\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Collecting python-multipart<0.0.10,>=0.0.9 (from litellm[proxy])\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from litellm[proxy]) (6.0.2)\n",
            "Collecting rq (from litellm[proxy])\n",
            "  Downloading rq-2.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting uvicorn<0.23.0,>=0.22.0 (from litellm[proxy])\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from apscheduler<4.0.0,>=3.10.4->litellm[proxy]) (1.16.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from apscheduler<4.0.0,>=3.10.4->litellm[proxy]) (2024.2)\n",
            "Requirement already satisfied: tzlocal!=3.*,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apscheduler<4.0.0,>=3.10.4->litellm[proxy]) (5.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<43.0.0,>=42.0.5->litellm[proxy]) (1.17.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi<0.112.0,>=0.111.0->litellm[proxy])\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<0.112.0,>=0.111.0->litellm[proxy]) (4.12.2)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi<0.112.0,>=0.111.0->litellm[proxy])\n",
            "  Downloading fastapi_cli-0.0.5-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<0.112.0,>=0.111.0->litellm[proxy]) (0.27.2)\n",
            "Collecting email_validator>=2.0.0 (from fastapi<0.112.0,>=0.111.0->litellm[proxy])\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from fastapi-sso<0.11.0,>=0.10.0->litellm[proxy]) (3.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gunicorn<23.0.0,>=22.0.0->litellm[proxy]) (24.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm[proxy]) (3.20.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm[proxy]) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm[proxy]) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm[proxy]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm[proxy]) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm[proxy]) (0.21.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.54.0->litellm[proxy]) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.54.0->litellm[proxy]) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.54.0->litellm[proxy]) (0.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.54.0->litellm[proxy]) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.54.0->litellm[proxy]) (4.66.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm[proxy]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm[proxy]) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->litellm[proxy]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->litellm[proxy]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->litellm[proxy]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->litellm[proxy]) (2024.8.30)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.7.0->litellm[proxy]) (2024.9.11)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn<0.23.0,>=0.22.0->litellm[proxy]) (0.14.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm[proxy]) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm[proxy]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm[proxy]) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm[proxy]) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm[proxy]) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm[proxy]) (4.0.3)\n",
            "Collecting redis>=3.5 (from rq->litellm[proxy])\n",
            "  Downloading redis-5.2.0-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers->litellm[proxy]) (0.26.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.54.0->litellm[proxy]) (1.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<43.0.0,>=42.0.5->litellm[proxy]) (2.22)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi<0.112.0,>=0.111.0->litellm[proxy])\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi<0.112.0,>=0.111.0->litellm[proxy]) (0.13.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi<0.112.0,>=0.111.0->litellm[proxy]) (1.0.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm[proxy]) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm[proxy]) (2024.9.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi<0.112.0,>=0.111.0->litellm[proxy]) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi<0.112.0,>=0.111.0->litellm[proxy]) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi<0.112.0,>=0.111.0->litellm[proxy]) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi<0.112.0,>=0.111.0->litellm[proxy]) (14.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->litellm[proxy]) (0.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<0.112.0,>=0.111.0->litellm[proxy]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<0.112.0,>=0.111.0->litellm[proxy]) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<0.112.0,>=0.111.0->litellm[proxy]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<0.112.0,>=0.111.0->litellm[proxy]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<0.112.0,>=0.111.0->litellm[proxy]) (0.1.2)\n",
            "Downloading APScheduler-3.10.4-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.3/59.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.111.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi_sso-0.10.0-py3-none-any.whl (16 kB)\n",
            "Downloading gunicorn-22.0.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading litellm-1.52.6-py3-none-any.whl (6.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rq-2.0.0-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.5/95.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi_cli-0.0.5-py3-none-any.whl (9.5 kB)\n",
            "Downloading redis-5.2.0-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, redis, python-multipart, gunicorn, dnspython, backoff, apscheduler, starlette, rq, pynacl, email_validator, cryptography, litellm, fastapi-cli, fastapi, fastapi-sso\n",
            "  Attempting uninstall: uvicorn\n",
            "    Found existing installation: uvicorn 0.32.0\n",
            "    Uninstalling uvicorn-0.32.0:\n",
            "      Successfully uninstalled uvicorn-0.32.0\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.41.2\n",
            "    Uninstalling starlette-0.41.2:\n",
            "      Successfully uninstalled starlette-0.41.2\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 43.0.3\n",
            "    Uninstalling cryptography-43.0.3:\n",
            "      Successfully uninstalled cryptography-43.0.3\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.115.5\n",
            "    Uninstalling fastapi-0.115.5:\n",
            "      Successfully uninstalled fastapi-0.115.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "vllm 0.6.3.post1 requires torch==2.4.0, but you have torch 2.2.2+cpu which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed apscheduler-3.10.4 backoff-2.2.1 cryptography-42.0.8 dnspython-2.7.0 email_validator-2.2.0 fastapi-0.111.1 fastapi-cli-0.0.5 fastapi-sso-0.10.0 gunicorn-22.0.0 litellm-1.52.6 pynacl-1.5.0 python-multipart-0.0.9 redis-5.2.0 rq-2.0.0 starlette-0.37.2 uvicorn-0.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Config.yaml\n",
        "model_list:\n",
        "  - model_name: gpt-3.5 # user-facing model alias\n",
        "    litellm_params: # all params accepted by litellm.completion() - https://docs.litellm.ai/docs/completion/input\n",
        "      model: openai/qwen2:0.5b\n",
        "      api_base: 'http://localhost:11434/v1'\n",
        "      api_key: 'sk_123'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evOLY3bDxA9S",
        "outputId": "8642318e-0fab-4eda-d6fc-a1adde37bc72"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup litellm --config Config.yaml &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGoSzqxExfX8",
        "outputId": "c9feff79-ada3-4d38-b086-c1f71419a855"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=\"anything\",\n",
        "    base_url=\"http://127.0.0.1:4000\"\n",
        ")\n",
        "model_name = \"gpt-3.5\"\n",
        "messages = [{\"role\": \"user\", \"content\": \"如何评价蔡徐坤?\"}]\n",
        "response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=messages,\n",
        "        )\n",
        "print(\"Chat response:\", response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoDdddafxgsv",
        "outputId": "4ac7c2d4-5e12-4e66-bce0-896dc7e0da94"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chat response: 蔡徐坤在音乐方面有着一定的知名度。他作为一位出生于1999年的华裔艺人，也是全球范围内的网络红人和公众人物。以下是对他的评价：\n",
            "\n",
            "1. 文化素养：蔡徐坤以其多才多艺的才华和艺术修养著称，他的歌曲、专辑和表演都展现了独特的音乐魅力。\n",
            "\n",
            "2. 舆论支持度：他在社交媒体上有着广泛的粉丝基础，他的个人品牌也获得了一定的认可。因此，在文化背景和社会关注度方面，他的评价要受到更多人的支持。\n",
            "\n",
            "3. 独特风格：蔡徐坤在演艺事业上的独特风格是他的最大的招牌，这种风格让许多人对他产生了深深的喜欢和追捧。\n",
            "\n",
            "4. 未来潜力：虽然作为艺人，他的人气已到顶峰，未来的潜力也极有可能达到高峰。然而，在接受媒体采访时，他表示自己还只是一个刚刚起步的新星，这意味着他在未来演艺路上还有很大的发展空间。\n",
            "\n",
            "5. 表演方面：蔡徐坤的演唱天赋和音乐才华使他对流行音乐领域有着卓越的贡献，他的表演艺术也是他的标志之一。\n",
            "\n",
            "尽管他在音乐方面的成就已经非常显著，在艺人排行榜上也有一定的地位，但随着年龄增长和社会环境的变化，他必须继续关注和提高自己的表现。在未来的日子里，蔡徐坤依然有巨大的潜力，值得我们对其持续支持和期待。\n",
            "\n",
            "以上是一个综合的评价框架，每个人都有所不同，因此对他的评价也应当是基于其个人发展的实际情况来定论，以求得到客观公正的答案。\n"
          ]
        }
      ]
    }
  ]
}